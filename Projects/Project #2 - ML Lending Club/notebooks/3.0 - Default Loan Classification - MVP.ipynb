{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None, 'display.max_rows', 100) \n",
    "\n",
    "from os import path\n",
    "import pickle\n",
    "\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV, cross_val_predict, learning_curve\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, fbeta_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load train set\n",
    "f = 'loan_train.p'\n",
    "d = ['..', 'data', 'processed']\n",
    "fp = path.join(*d, f)\n",
    "\n",
    "with open(fp, 'rb') as file:\n",
    "    train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load train target set\n",
    "f = 'loan_train_target.p'\n",
    "d = ['..', 'data', 'processed']\n",
    "fp = path.join(*d, f)\n",
    "\n",
    "with open(fp, 'rb') as file:\n",
    "    train_target = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load test set\n",
    "f = 'loan_test.p'\n",
    "d = ['..', 'data', 'processed']\n",
    "fp = path.join(*d, f)\n",
    "\n",
    "with open(fp, 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load test target set\n",
    "f = 'loan_test_target.p'\n",
    "d = ['..', 'data', 'processed']\n",
    "fp = path.join(*d, f)\n",
    "\n",
    "with open(fp, 'rb') as file:\n",
    "    test_target = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152218, 47), (152218, 2))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38055, 47), (38055, 2))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class for selecting attributes from a dataframe, for use in pipelines\n",
    "\n",
    "class DataFrame_Selector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    def get_feature_names(self):\n",
    "        return self.attribute_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts categorical features into OHE features using pandas get_dummies.\n",
    "# Can take a list of valid dummy column names to ensure consistency between data sets with different categorical values.\n",
    "class DataFrame_DummyEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, attribute_names, valid_dummy_cols=None):\n",
    "        self.attribute_names = attribute_names\n",
    "        # In case categorical values differ between datasets\n",
    "        self.valid_dummy_cols = valid_dummy_cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.valid_dummy_cols is not None:\n",
    "            zero_data = np.zeros(shape=(len(X),len(self.valid_dummy_cols)))\n",
    "            self.dummies = pd.DataFrame(zero_data, columns=self.valid_dummy_cols)\n",
    "            d = pd.get_dummies(X[self.attribute_names])\n",
    "\n",
    "            for col in d.columns:\n",
    "                if col in self.dummies.columns:\n",
    "                    self.dummies[col] = d[col].values\n",
    "        else:\n",
    "            self.dummies = pd.get_dummies(X[self.attribute_names])\n",
    "        return self.dummies.values\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.dummies.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2db9b02bbd74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mCustomNumAttributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreference_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomNumAttributes(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, ref_dict=None):\n",
    "        self.ref_dict = ref_dict\n",
    "    def fit(self, data, y=None):\n",
    "        return self\n",
    "    def transform(self, data, y=None):\n",
    "        X = data.copy()\n",
    "        # Note: following assumes that X is still be a pandas DataFrame vs. numpy array. \n",
    "        self.custom_attr_names = []\n",
    "        ###\n",
    "        grade_map = {grade: i for i, grade in enumerate('ABCDEFG')}\n",
    "        X['grade_value'] = X['grade'].map(grade_map)\n",
    "        self.custom_attr_names.append('grade_value')\n",
    "        ###\n",
    "        subgrade_map = {sg: grade_map[sg[0]]*10 + int(sg[1]) for sg in [c + str(i) for c in 'ABCDEFG' for i in range(1,6)]}\n",
    "        X['subgrade_value'] = X['sub_grade'].map(subgrade_map)\n",
    "        self.custom_attr_names.append('subgrade_value')\n",
    "        ###\n",
    "        X['lti'] = X['funded_amnt'] / X['annual_inc']\n",
    "        X['iti'] = X['installment'] / X['annual_inc']\n",
    "        X['rbti'] = X['revol_bal'] / X['annual_inc']\n",
    "        X['tbti'] = X['tot_cur_bal'] / X['annual_inc']\n",
    "        self.custom_attr_names.append(['lti', 'iti', 'rbti', 'tbti'])\n",
    "        ###\n",
    "        X['revol_bal_log'] = X['revol_bal'].apply(lambda x: np.log10(x) if x >= 1 else 0)\n",
    "        X['tot_coll_log'] = X['tot_coll_amt'].apply(lambda x: np.log10(x) if x >= 1 else 0)\n",
    "        X['rev_lim_log'] = X['total_rev_hi_lim'].apply(lambda x: np.log10(x) if x >= 1 else 0)\n",
    "        X['rev_lim_sqrt'] = np.sqrt(X['total_rev_hi_lim'])\n",
    "        self.custom_attr_names.append(['revol_bal_log', 'tot_coll_log', 'rev_lim_log', 'rev_lim_sqrt'])\n",
    "        ###\n",
    "        X['earliest_cr_line_td'] = [(issue_d.date() - cr.date()).days for issue_d, cr in zip(X['issue_d'], X['earliest_cr_line'])]\n",
    "        X['cr_line_td_log'] = X['earliest_cr_line_td'].apply(lambda x: np.log10(x) if x >= 1 else 0)\n",
    "        self.custom_attr_names.append(['earliest_cr_line_td', 'cr_line_td_log'])\n",
    "        ###\n",
    "        ref_dict = self.ref_dict\n",
    "        if ref_dict is not None:\n",
    "            ###\n",
    "            if 'grade_p_map' in ref_dict:\n",
    "                X['grade_p_value'] = X['grade'].map(ref_dict['grade_p_map'])\n",
    "                self.custom_attr_names.append('grade_p_value')\n",
    "            ###\n",
    "            if 'subgrade_p_map' in ref_dict:\n",
    "                X['subgrade_p_value'] = X['sub_grade'].map(ref_dict['subgrade_p_map'])\n",
    "                self.custom_attr_names.append('subgrade_p_value')\n",
    "            ###\n",
    "            if ('subgrade_int_rate_mean' in ref_dict) and ('subgrade_int_rate_std' in ref_dict):\n",
    "                X['int_rate_delta'] = X[['int_rate','sub_grade']].apply(lambda x: (x['int_rate'] - ref_dict['subgrade_int_rate_mean'][x['sub_grade']]) / ref_dict['subgrade_int_rate_std'][x['sub_grade']], axis=1)\n",
    "                self.custom_attr_names.append('int_rate_delta')\n",
    "            ###\n",
    "            if 'annual_inc_q10' in ref_dict:\n",
    "                X['annual_inc_q10'] = X['annual_inc'].apply(lambda x: len(ref_dict['annual_inc_q10']) if x > max(ref_dict['annual_inc_q10']) else np.argmax(x <= ref_dict['annual_inc_q10'])+1)\n",
    "                self.custom_attr_names.append('annual_inq_q10')\n",
    "            ##\n",
    "            if 'funded_amnt_q10' in ref_dict:\n",
    "                X['funded_amnt_q10'] = X['funded_amnt'].apply(lambda x: len(ref_dict['funded_amnt_q10']) if x > max(ref_dict['funded_amnt_q10']) else np.argmax(x <= ref_dict['funded_amnt_q10'])+1)\n",
    "                self.custom_attr_names.append('funded_amnt_q10')\n",
    "            ###\n",
    "        return X\n",
    "    def get_feature_names(self):\n",
    "        return self.custom_attr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomBinAttributes(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, data, y=None):\n",
    "        return self\n",
    "    def transform(self, data, y=None):\n",
    "        X = data.copy()        \n",
    "        # Note: following assumes that X is still be a pandas DataFrame vs. numpy array. \n",
    "        self.custom_attr_names = []\n",
    "        ###\n",
    "        X['verified'] = (X['verification_status'] != 'Not Verified').astype(int)\n",
    "        self.custom_attr_names.append('verified')\n",
    "        ###\n",
    "        return X\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reference_stats(reference_data):\n",
    "    d = {}\n",
    "    data = reference_data.copy()\n",
    "    default = data['loan_status'].str.contains('Charged Off|Default').astype(int)\n",
    "    d['grade_p_map'] = default.groupby(data['grade']).mean()\n",
    "    d['subgrade_p_map'] = default.groupby(data['sub_grade']).mean()\n",
    "    \n",
    "    d['subgrade_int_rate_mean'] = data.groupby('sub_grade')['int_rate'].mean()\n",
    "    d['subgrade_int_rate_std'] = data.groupby('sub_grade')['int_rate'].std()\n",
    "    \n",
    "    d['annual_inc_q10'] = data['annual_inc'].quantile(np.arange(0.1, 1.1, 0.1))\n",
    "    d['funded_amnt_q10'] = data['funded_amnt'].quantile(np.arange(0.1, 1.1, 0.1))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns identified thus far as best for classification (during data prep, select K best)\n",
    "num_attr = ['funded_amnt_q10', 'int_rate_delta', 'annual_inc_q10', 'dti', 'delinq_2yrs', 'inq_last_6mths',\n",
    "            'open_acc', 'revol_bal_log', 'revol_util', 'total_acc', 'collection_recovery_fee', 'collections_12_mths_ex_med',\n",
    "            'acc_now_delinq', 'rev_lim_sqrt', 'tot_cur_bal', 'tot_coll_amt', 'subgrade_p_value',\n",
    "            'lti', 'rbti', 'tbti', 'cr_line_td_log']\n",
    "\n",
    "bin_attr = ['had_delinq', 'had_major_derog', 'had_record', 'verified']\n",
    "\n",
    "cat_attr = ['emp_length', 'purpose', 'home_ownership', 'term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get list of valid dummy columns from full data set\n",
    "train_ref_stats = reference_stats(train)\n",
    "train_dummy_cols = pd.get_dummies(train[cat_attr]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_prep = Pipeline([('custom', CustomNumAttributes(ref_dict=train_ref_stats)),\n",
    "                     ('select', DataFrame_Selector(num_attr)), # Select num columns\n",
    "                     ('sc', StandardScaler())]) # Scale data\n",
    "\n",
    "bin_prep = Pipeline([('custom', CustomBinAttributes()),\n",
    "                     ('select', DataFrame_Selector(bin_attr))]) # Select binary columns\n",
    "\n",
    "cat_prep = Pipeline([('encode', DataFrame_DummyEncoder(cat_attr, train_dummy_cols))]) # Select & encode categrocial columns\n",
    "\n",
    "feature_prep = FeatureUnion([('num', num_prep),\n",
    "                             ('bin', bin_prep),\n",
    "                             ('cat', cat_prep)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = feature_prep.fit_transform(train)\n",
    "y = train_target['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = feature_prep.transform(test)\n",
    "y_test = test_target['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152218, 57), (152218,))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38055, 57), (38055,))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the training set further into a training and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((121774, 57), (121774,))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30444, 57), (30444,))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize dict for models\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_time(reset=False, return_time=False):\n",
    "    if reset:\n",
    "        run_time.start_time = time.time()\n",
    "    else:\n",
    "        td = time.time()-run_time.start_time\n",
    "        m = td//60\n",
    "        s = td%60\n",
    "        ms = 1000*(s%1)\n",
    "        display = 'Time: '\n",
    "        display += ('{:.0f}min '.format(m) if m > 0 else '')\n",
    "        display += ('{:.0f}s '.format(s) if (s > 1 and m > 0) else ('{:.2f}s '.format(s) if (s > 1) else ''))\n",
    "        display += ((str(round(ms))+'ms ') if (s < 1) else '')\n",
    "        print(display)\n",
    "        if return_time:\n",
    "            return td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier_summary(y_actual, y_pred, print_results=True): \n",
    "    \n",
    "    #f1 = f1_score(y_actual, y_pred)\n",
    "    f2 = fbeta_score(y_actual, y_pred, beta=2)\n",
    "    recall = recall_score(y_actual, y_pred)\n",
    "    precision = precision_score(y_actual, y_pred)\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_actual, y_pred)\n",
    "    \n",
    "    specificity = conf_mat[0,0] / (conf_mat[0,:].sum())\n",
    "    fallout = 1 - specificity\n",
    "    precision_neg = conf_mat[0,0] / (conf_mat[:,0].sum())\n",
    "    \n",
    "    df_cmat = pd.DataFrame(conf_mat).rename(index={0:'Actual Negative', 1:'Actual Positive'},\n",
    "                                  columns={0:'Predicted Negative', 1:'Predicted Positive'})\n",
    "    \n",
    "    df_scores = pd.DataFrame([{'Rate': 'F2', 'Score': f2},\n",
    "                              {'Rate': 'Recall', 'Score': recall},\n",
    "                              {'Rate': 'Precision (pos)', 'Score': precision},\n",
    "                              {'Rate': 'Precision (neg)', 'Score': precision_neg},\n",
    "                              {'Rate': 'Specificity', 'Score': specificity}]).set_index('Rate')\n",
    "    \n",
    "    if print_results:\n",
    "        print('Confusion Matrix:')\n",
    "        print(df_cmat)\n",
    "        print(20*'-')\n",
    "        print('Accuracy Scores:')\n",
    "        print(df_scores)\n",
    "   \n",
    "    return df_cmat, df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gs_score_summary(gs):\n",
    "    scores = gs.scoring\n",
    "    print('-'*20)\n",
    "    for score in scoring:\n",
    "        i = np.argmin(gs.cv_results_['rank_test_' + str(score)])\n",
    "        print('Best {}:'.format(score.title()))\n",
    "        print('Params: {}'.format(gs.cv_results_['params'][i]))\n",
    "\n",
    "        for s in scores:\n",
    "            print('{} = {}'.format(s.title(), gs.cv_results_['mean_test_'+str(s)][i]))\n",
    "        print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_cvs(cvs, scoring='CV'):\n",
    "    print('Mean {} score = {:.3f} (+\\- {:.3f})'.format(scoring, cvs.mean(), cvs.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Measuring Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business problem at hand for this classification problem is to identify loans that will default. In terms of measuring the performance of our models, the question arises as to which method of scoring / accuracy we value most. In the context of investing in loans, the risks and consequences of failing to identify a default loan greatly outweight those of accidentally discarding some quality loans as default. With this premise, recall (i.e. the proportion of actual default loans identified) should be score we seek to maximize.\n",
    "\n",
    "However, attempts to boost recall will inevitabely reduce model precision. In an extreme yet possible example, a model that is optimized to identify 90% of default loans could come at the cost of discarding 90% of non-default loans (i.e. 50% precision). From a business standpoint this would leave an unreasonable number of viable loans in the pool of non-default predictions. Consequently, a better approach for optimizing our models is to use an F beta scoring in which recall is given more weight than precision (i.e. beta > 1).\n",
    "\n",
    "We will proceed with using F2 scoring (beta = 2), in which recall is essentially valued twice as much as precision. This should hopefully allow to us to still maximize recall to a certain degree without decreasing precision to unnacceptable levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f2_score = make_scorer(fbeta_score, beta=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy classifier (stratified):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_strat = DummyClassifier(strategy='stratified')\n",
    "dummy_strat.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_strat_train_pred = dummy_strat.predict(X_train)\n",
    "dummy_strat_val_pred = dummy_strat.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               79768               18546\n",
      "Actual Positive               18958                4502\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.192578\n",
      "Recall           0.191901\n",
      "Precision (pos)  0.195331\n",
      "Precision (neg)  0.807974\n",
      "Specificity      0.811360\n"
     ]
    }
   ],
   "source": [
    "classifier_summary(y_train, dummy_strat_train_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               19794                4836\n",
      "Actual Positive                4696                1118\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.191373\n",
      "Recall           0.192294\n",
      "Precision (pos)  0.187773\n",
      "Precision (neg)  0.808248\n",
      "Specificity      0.803654\n"
     ]
    }
   ],
   "source": [
    "classifier_summary(y_val, dummy_strat_val_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy classifier (unfirom):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='uniform')"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_uniform = DummyClassifier(strategy='uniform')\n",
    "dummy_uniform.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_uniform_train_pred = dummy_uniform.predict(X_train)\n",
    "dummy_uniform_val_pred = dummy_uniform.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               48942               49372\n",
      "Actual Positive               11664               11796\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.380496\n",
      "Recall           0.502813\n",
      "Precision (pos)  0.192846\n",
      "Precision (neg)  0.807544\n",
      "Specificity      0.497813\n"
     ]
    }
   ],
   "source": [
    "classifier_summary(y_train, dummy_uniform_train_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               12352               12278\n",
      "Actual Positive                2899                2915\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.379074\n",
      "Recall           0.501376\n",
      "Precision (pos)  0.191865\n",
      "Precision (neg)  0.809914\n",
      "Specificity      0.501502\n"
     ]
    }
   ],
   "source": [
    "classifier_summary(y_val, dummy_uniform_val_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two dummy classifiers reperesent opposite extremes of our modelling potential. The stratified predictions predict defaults infrequently due to its small class proportion, resulting in high specificity but very low recall & precisons scores.\n",
    "\n",
    "The uniform predictor, on the other hand, boosts the frequency of predicted default loans resulting in a much better recall but still with low precision.\n",
    "\n",
    "Due to the higher recall scores with our uniform predictor we see a significant improvement in the F2 score, so this is probably "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another baseline model which should provide a better compromise between these two extremes is a one rule classifier (single level decision tree):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_r = DecisionTreeClassifier(max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oner_f2_cvs = cross_val_score(estimator=one_r, X=X_train, y=y_train, cv=5, scoring=f2_score, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.534 (+\\- 0.004)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(oner_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_r_train_pred = branch.predict(X_train)\n",
    "one_r_val_pred = branch.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               98314                   0\n",
      "Actual Positive               13073               10387\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.498287\n",
      "Recall           0.442754\n",
      "Precision (pos)  1.000000\n",
      "Precision (neg)  0.882634\n",
      "Specificity      1.000000\n"
     ]
    }
   ],
   "source": [
    "classifier_summary(y_train, one_r_train_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               24630                   0\n",
      "Actual Positive                3198                2616\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.505566\n",
      "Recall           0.449948\n",
      "Precision (pos)  1.000000\n",
      "Precision (neg)  0.885080\n",
      "Specificity      1.000000\n"
     ]
    }
   ],
   "source": [
    "classifier_summary(y_val, one_r_val_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic model, no tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.05 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr_timeit = %timeit -n1 -r1 -o \\\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad fit time with 4 seconds. Let's see how the base model performs with cross validation scores (f1 and recall):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_f2_cvs = cross_val_score(estimator=logreg,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=5,\n",
    "                             scoring=f2_score,\n",
    "                             n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.505 (+\\- 0.002)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(lr_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_train_pred = lr.predict(X_train)\n",
    "lr_val_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               98221                  93\n",
      "Actual Positive               13647                9813\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.472934\n",
      "Recall           0.418286\n",
      "Precision (pos)  0.990612\n",
      "Precision (neg)  0.878008\n",
      "Specificity      0.999054\n"
     ]
    }
   ],
   "source": [
    "lr_train_summary = classifier_summary(y_train, lr_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               24600                  30\n",
      "Actual Positive                3343                2471\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.479675\n",
      "Recall           0.425009\n",
      "Precision (pos)  0.988005\n",
      "Precision (neg)  0.880364\n",
      "Specificity      0.998782\n"
     ]
    }
   ],
   "source": [
    "lr_val_summary = classifier_summary(y_val, lr_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are very precise as there are hardly any false positives. However, our recall score of interest is in dire need of improvement since we are only identifying 42% of the actual defaulted loans. Our CV, train, and validation sets all perform similarly, so at least there is little indication of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting the small proportion of defaulted loans, using a balanced class weight may yield more favorable results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "lr_bal = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "lr_bal_timeit = %timeit -n1 -r1 -o \\\n",
    "lr_bal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_bal_f2_cvs = cross_val_score(estimator=lr_bal,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=5,\n",
    "                             scoring=f2_score,\n",
    "                             n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.599 (+\\- 0.003)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(lr_bal_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrb_train_pred = lr_bal.predict(X_train)\n",
    "lrb_val_pred = lr_bal.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               84469               13845\n",
      "Actual Positive                8359               15101\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.614932\n",
      "Recall           0.643691\n",
      "Precision (pos)  0.521696\n",
      "Precision (neg)  0.909952\n",
      "Specificity      0.859176\n"
     ]
    }
   ],
   "source": [
    "lrb_train_summary = classifier_summary(y_train, lrb_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               21211                3419\n",
      "Actual Positive                2080                3734\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.613963\n",
      "Recall           0.642243\n",
      "Precision (pos)  0.522019\n",
      "Precision (neg)  0.910695\n",
      "Specificity      0.861186\n"
     ]
    }
   ],
   "source": [
    "lrb_val_summary = classifier_summary(y_val, lrb_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing the class weights yields significant improvements to the recall & F2 score, as the increased weight for our default class leads to more loans being flagged as such. However, the consequence is that precision is decreased considerably - from 0.99 to 0.52. This means that with this approach, approx. half the loans identified as default are in fact false positives. However, our false negative rate (denoted 'Precision (neg)') actually improves slightly, meaning the loans that remain as predicted negative have a higher guarantee of actually being non-default. Additionally, specificity only decreases slightly, so the fraction of non-default loans lost to false positive classification is proportionally small.\n",
    "\n",
    "All in all given these results and our overall increase in F2 score, logistic regression shows promise as a model worth exploring and tuning further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "gnb_time = %timeit -n1 -r1 -o \\\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb_f2_cvs = cross_val_score(estimator=gnb, X=X_train, y=y_train, cv=5, scoring=f2_score, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.533 (+\\- 0.005)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(gnb_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb_train_pred = gnb.predict(X_train)\n",
    "gnb_val_pred = gnb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               96110                2204\n",
      "Actual Positive               12663               10797\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.505284\n",
      "Recall           0.460230\n",
      "Precision (pos)  0.830475\n",
      "Precision (neg)  0.883583\n",
      "Specificity      0.977582\n"
     ]
    }
   ],
   "source": [
    "gnb_train_summary = classifier_summary(y_train, gnb_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               24091                 539\n",
      "Actual Positive                3096                2718\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.512579\n",
      "Recall           0.467492\n",
      "Precision (pos)  0.834510\n",
      "Precision (neg)  0.886122\n",
      "Specificity      0.978116\n"
     ]
    }
   ],
   "source": [
    "gnb_val_summary = classifier_summary(y_val, gnb_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive Bayes classifier seems to show similar performance in terms of recall to our non-balanced logistic regression model, with a slight improvement to recall and reduction in precision. The class probabilities should already be accounted for by default, so it is possible this model is suffering from high dimensionality given our 57 features. Additionally, with the large training set size of 120,000 records it is also possible the distinction between classes is muddled by the amount of overlapping data, however this seems less likely since both the k-fold cross validated and full training set scores are almost identical.\n",
    "\n",
    "Regardless, we will see if training set size shows any improvements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_ind = np.random.choice(np.arange(0, X_train.shape[0], 1), size=10000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sample = X_train[rand_ind]\n",
    "y_train_sample = y_train.iloc[rand_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb_s = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "gnb_s_time = %timeit -n1 -r1 -o \\\n",
    "gnb_s.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb_s_f2_cvs = cross_val_score(estimator=gnb_s, X=X_train_sample, y=y_train_sample, cv=5, scoring=f2_score, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.557 (+\\- 0.033)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(gnb_s_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb_s_train_pred = gnb_s.predict(X_train)\n",
    "gnb_s_val_pred = gnb_s.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               95613                2701\n",
      "Actual Positive               12337               11123\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.516561\n",
      "Recall           0.474126\n",
      "Precision (pos)  0.804615\n",
      "Precision (neg)  0.885716\n",
      "Specificity      0.972527\n"
     ]
    }
   ],
   "source": [
    "gnb_train_summary = classifier_summary(y_train, gnb_s_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               23981                 649\n",
      "Actual Positive                3022                2792\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.522905\n",
      "Recall           0.480220\n",
      "Precision (pos)  0.811392\n",
      "Precision (neg)  0.888087\n",
      "Specificity      0.973650\n"
     ]
    }
   ],
   "source": [
    "gnb_val_summary = classifier_summary(y_val, gnb_s_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very slight improvements. Compared to our balanced class weight Logistic Regression model, these results are still signficantly worse, and only a slight improvement over the OneR decision tree baseline. However, it may be worth exploring the optimal training size further to maximize and implement GNB as via bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = Pipeline([('norm', Normalizer()),\n",
    "                ('estimator', KNeighborsClassifier(n_jobs=2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "knn_time = %timeit -n1 -r1 -o \\\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_f2_cvs = cross_val_score(estimator=knn, X=X_train, y=y_train, cv=3, scoring=f2_score, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.304 (+\\- 0.004)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(knn_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already looking to be significantly worse than the other models tested until now, but this could also be a result of the fold sample sizes not providing sufficient information. Predictions using KNN are also likely to take some time due to its nature of having to process the entire set each time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11min 23s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 \\\n",
    "knn_train_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_val_pred = knn.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the nature of KNN these predictions took signficantly longer for predictions than our other models thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               94452                3862\n",
      "Actual Positive               12242               11218\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.514965\n",
      "Recall           0.478176\n",
      "Precision (pos)  0.743899\n",
      "Precision (neg)  0.885261\n",
      "Specificity      0.960718\n"
     ]
    }
   ],
   "source": [
    "knn_train_summary = classifier_summary(y_train, knn_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               23538                1092\n",
      "Actual Positive                4324                1490\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.288335\n",
      "Recall           0.256278\n",
      "Precision (pos)  0.577072\n",
      "Precision (neg)  0.844807\n",
      "Specificity      0.955664\n"
     ]
    }
   ],
   "source": [
    "knn_val_summary = classifier_summary(y_val, knn_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN clearly suffers from overfitting given the performance with our validation set (and the CV scores). Perhaps reducing the training size has an impact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_ind = np.random.choice(np.arange(0, X_train.shape[0], 1), size=10000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sample = X_train[rand_ind]\n",
    "y_train_sample = y_train.iloc[rand_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=2, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_s = KNeighborsClassifier(n_jobs=2)\n",
    "knn_s.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_s_f2_cvs = cross_val_score(estimator=knn_s, X=X_train_sample, y=y_train_sample, cv=3, scoring=f2_score, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV score = 0.261 (+\\- 0.020)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(knn_s_f2_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_s_val_pred = knn_s.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               23581                1049\n",
      "Actual Positive                4546                1268\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.247918\n",
      "Recall           0.218094\n",
      "Precision (pos)  0.547259\n",
      "Precision (neg)  0.838376\n",
      "Specificity      0.957410\n"
     ]
    }
   ],
   "source": [
    "classifier_summary(y_val, knn_s_val_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the sample size (although just one scenario) shows a decrease in performance. Perhaps some parameter tuning may show improvements but relative to other model performances seen thus far it may be difficult to reach similar levels of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifiers are likely to be computationally expensive due to the number of features, but we will still give it a try and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "lsvc_time = %timeit -n1 -r1 -o \\\n",
    "lsvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat slower due to large number of training instances n (160k) and features m (59). (complexity $O(m\\times n)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_f2_cvs = cross_val_score(estimator=LinearSVC(), X=X_train, y=y_train, cv=5, scoring=f2_score, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV score = 0.524 (+\\- 0.003)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(lsvc_f2_cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any tuning this already seems to be better than our base logisitic regression model, with slight improvements over the OneR decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_train_pred = lin_svc.predict(X_train)\n",
    "lsvc_val_pred = lin_svc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               98314                   0\n",
      "Actual Positive               13290               10170\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.488895\n",
      "Recall           0.433504\n",
      "Precision (pos)  1.000000\n",
      "Precision (neg)  0.880918\n",
      "Specificity      1.000000\n"
     ]
    }
   ],
   "source": [
    "lsvc_train_summary = classifier_summary(y_train, lsvc_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               24630                   0\n",
      "Actual Positive                3253                2561\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.495991\n",
      "Recall           0.440488\n",
      "Precision (pos)  1.000000\n",
      "Precision (neg)  0.883334\n",
      "Specificity      1.000000\n"
     ]
    }
   ],
   "source": [
    "lsvc_val_summary = classifier_summary(y_val, lsvc_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results on the train and validation set are very much like our initial logistic regression model, which bring up the same issue of class weights. Trying the balanced class weight approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_b = LinearSVC(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "lsvc_b_time = %timeit -n1 -r1 -o \\\n",
    "lsvc_b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_b_f2_cvs = cross_val_score(estimator=lsvc_b, X=X_train, y=y_train, cv=5, scoring=f2_score, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV score = 0.600 (+\\- 0.002)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(lsvc_b_f2_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_b_train_pred = lsvc_b.predict(X_train)\n",
    "lsvc_b_val_pred = lsvc_b.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               85900               12414\n",
      "Actual Positive                8648               14812\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.611732\n",
      "Recall           0.631373\n",
      "Precision (pos)  0.544039\n",
      "Precision (neg)  0.908533\n",
      "Specificity      0.873731\n"
     ]
    }
   ],
   "source": [
    "lsvc_b_train_summary = classifier_summary(y_train, lsvc_b_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               21569                3061\n",
      "Actual Positive                2132                3682\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.613687\n",
      "Recall           0.633299\n",
      "Precision (pos)  0.546048\n",
      "Precision (neg)  0.910046\n",
      "Specificity      0.875721\n"
     ]
    }
   ],
   "source": [
    "lsvc_b_val_summary = classifier_summary(y_val, lsvc_b_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with our balanced class weight logistic regression model, we see a signficant boost to recall (and consequently F2). Compared to our baseline OneR model this is already a signficant improvement, and consequently should be explored more in depth with parameter and feature tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Classifier - Polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial SVC will take an exceptionally long time to fit given the size our training set. However, fitting the model on a sample of the training data may at least give some insight into how the model compares to others. Noting the improvements acheived via balanced class weights we will proceed with the same setting here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_ind = np.random.choice(np.arange(0, X_train.shape[0], 1), size=20000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sample = X_train[rand_ind]\n",
    "y_train_sample = y_train.iloc[rand_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psvc = SVC(kernel='poly', degree=2, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.5 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "psvc_time = %timeit -n1 -r1 -o \\\n",
    "psvc.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with 20,000 samples this is one of the slower fitting times yet (ignoring the prediction time for KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psvc_f2_cvs = cross_val_score(estimator=psvc, X=X_train_sample, y=y_train_sample, cv=5, scoring=f2_score, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.503 (+\\- 0.022)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(psvc_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psvc_train_pred = psvc.predict(X_train)\n",
    "psvc_val_pred = psvc.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with the reduced sample these predictions take a considerable amount of time to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               78491               19823\n",
      "Actual Positive                9544               13916\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.545388\n",
      "Recall           0.593180\n",
      "Precision (pos)  0.412460\n",
      "Precision (neg)  0.891589\n",
      "Specificity      0.798371\n"
     ]
    }
   ],
   "source": [
    "psvc_train_summary = classifier_summary(y_train, psvc_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               19748                4882\n",
      "Actual Positive                2389                3425\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.542566\n",
      "Recall           0.589095\n",
      "Precision (pos)  0.412303\n",
      "Precision (neg)  0.892081\n",
      "Specificity      0.801786\n"
     ]
    }
   ],
   "source": [
    "psvc_val_summary = classifier_summary(y_val, psvc_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performance is a slight improvement over the baseline OneR model, however it pales slightly compared to the linear SVC classifier with balanced weights. Additionally, precision has suffered significantly versus the linear model. This could be a result of the reduced training set size, so if time permits this could be invesigated further with a larger set, perhaps in tandem with reduced dimensionality to aid in computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Classifier  - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_ind = np.random.choice(np.arange(0, X_train.shape[0], 1), size=20000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sample = X_train[rand_ind]\n",
    "y_train_sample = y_train.iloc[rand_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rsvc = SVC(kernel='rbf', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "rsvc_time = %timeit -n1 -r1 -o \\\n",
    "rsvc.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparable fit time to our polynomial SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rsvc_f2_cvs = cross_val_score(estimator=rsvc, X=X_train_sample, y=y_train_sample, cv=5, scoring=f2_score, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.546 (+\\- 0.016)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(rsvc_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rsvc_train_pred = rsvc.predict(X_train)\n",
    "rsvc_val_pred = rsvc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               80301               18013\n",
      "Actual Positive                8953               14507\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.574035\n",
      "Recall           0.618372\n",
      "Precision (pos)  0.446095\n",
      "Precision (neg)  0.899691\n",
      "Specificity      0.816781\n"
     ]
    }
   ],
   "source": [
    "rsvc_train_summary = classifier_summary(y_train, rsvc_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               20156                4474\n",
      "Actual Positive                2280                3534\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.565187\n",
      "Recall           0.607843\n",
      "Precision (pos)  0.441309\n",
      "Precision (neg)  0.898378\n",
      "Specificity      0.818352\n"
     ]
    }
   ],
   "source": [
    "rsvc_val_summary = classifier_summary(y_val, rsvc_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF actually performed slightly better than the polynomial SVC. It is still not quite as succesful in terms of F2, with precision again taking a notable dip (albeit slightly less than polynomial SVC). Consequently, if additional SVC models are to be pursued (besides linear), RBF may be more worthwhile to investigate further over polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our OneR baseline model is already a decision tree model, but perhaps some basic tuning can provide some immediate improvements. Firstly, we will evaluate a completely unconstrained decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_f2_cvs = cross_val_score(estimator=dtc, X=X_train, y=y_train, cv=5, scoring=f2_score, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.539 (+\\- 0.004)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(dtc_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially identical F2 CV score to the OneR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_train_pred = dtc.predict(X_train)\n",
    "dtc_val_pred = dtc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               98314                   0\n",
      "Actual Positive                   0               23460\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                 Score\n",
      "Rate                  \n",
      "F2                 1.0\n",
      "Recall             1.0\n",
      "Precision (pos)    1.0\n",
      "Precision (neg)    1.0\n",
      "Specificity        1.0\n"
     ]
    }
   ],
   "source": [
    "dtc_train_summary = classifier_summary(y_train, dtc_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               21589                3041\n",
      "Actual Positive                2606                3208\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.543637\n",
      "Recall           0.551772\n",
      "Precision (pos)  0.513362\n",
      "Precision (neg)  0.892292\n",
      "Specificity      0.876533\n"
     ]
    }
   ],
   "source": [
    "dtc_val_summary = classifier_summary(y_val, dtc_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the difference between our training scores and CV / validation scores, this unconstrained decision tree is clearly suffering from extreme overfitting. We will see if adding some basic constraints shows some improvements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=30, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_v2 = RandomForestClassifier(max_depth=30, min_samples_split=50, class_weight='balanced')\n",
    "dtc_v2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_v2_f1_cvs = cross_val_score(estimator=dtc_v2, X=X_train, y=y_train, cv=5, scoring=f2_score, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.583 (+\\- 0.003)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(dtc_v2_f1_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_v2_train_pred = dtc_v2.predict(X_train)\n",
    "dtc_v2_val_pred = dtc_v2.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               94018                4296\n",
      "Actual Positive                5721               17739\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.765437\n",
      "Recall           0.756138\n",
      "Precision (pos)  0.805037\n",
      "Precision (neg)  0.942640\n",
      "Specificity      0.956303\n"
     ]
    }
   ],
   "source": [
    "dtc_v2_train_summary = classifier_summary(y_train, dtc_v2_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               22959                1671\n",
      "Actual Positive                2560                3254\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.577339\n",
      "Recall           0.559684\n",
      "Precision (pos)  0.660711\n",
      "Precision (neg)  0.899683\n",
      "Specificity      0.932156\n"
     ]
    }
   ],
   "source": [
    "dtc_v2_val_summary = classifier_summary(y_val, dtc_v2_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst overfitting is clearly still an issue, adding some basic, rather arbitrary constraints already shows improvement. In tandem with grid/random search, it should be hopefully be possible to reach similar success in recall / F2 score as our linear regression and SVC models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add model to list\n",
    "model = {'model_name': 'Decision Tree (Basic)',\n",
    "         'model_type':'DecisionTreeClassifier',\n",
    "         'model': dtc,\n",
    "         'train_score': train_scores.iloc[0,0],\n",
    "         'test_score': test_scores.iloc[0,0]}\n",
    "\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests are simply collections of decision trees, so we can carry forward what we have learned so far with our initial model, but will constrain our tree a little more for the ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=20, max_depth=10, min_samples_split=100, class_weight='balanced', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=10, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=100, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=2, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_f2_cvs = cross_val_score(estimator=rfc, X=X_train, y=y_train, cv=5, scoring=f2_score, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.600 (+\\- 0.003)\n"
     ]
    }
   ],
   "source": [
    "print_cvs(rfc_f2_cvs, 'f2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CV score is a promising start. Let us see how it fares in terms of train vs. validation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_train_pred = rfc.predict(X_train)\n",
    "rfc_val_pred = rfc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               83342               14972\n",
      "Actual Positive                7205               16255\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.649852\n",
      "Recall           0.692882\n",
      "Precision (pos)  0.520543\n",
      "Precision (neg)  0.920428\n",
      "Specificity      0.847712\n"
     ]
    }
   ],
   "source": [
    "rfc_train_summary = classifier_summary(y_train, rfc_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               20738                3892\n",
      "Actual Positive                1944                3870\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.623831\n",
      "Recall           0.665635\n",
      "Precision (pos)  0.498583\n",
      "Precision (neg)  0.914293\n",
      "Specificity      0.841981\n"
     ]
    }
   ],
   "source": [
    "rfc_val_summary = classifier_summary(y_val, rfc_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is clearly less affected by the overfitting issues seen with the individual decision tree. Regardess of how much this is a result of the constraint parameters versus the collection of 20 estimators, random forest is definitely one of the better performing models and worth pursuing further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
