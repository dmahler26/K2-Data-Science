{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None, 'display.max_rows', 100) \n",
    "\n",
    "from os import path\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import src.functions.my_functions as my_func\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, fbeta_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, SelectPercentile, RFECV, RFE, f_classif\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.functions.my_functions' from '..\\\\src\\\\functions\\\\my_functions.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imp import reload\n",
    "reload(my_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "ds = ['train', 'train_target', 'test', 'test_target']\n",
    "d = ['..', 'data', 'processed']\n",
    "\n",
    "for s in ds:    \n",
    "    fn = 'loan_'+s+'.p'\n",
    "    fp = path.join(*d, fn)\n",
    "\n",
    "    with open(fp, 'rb') as file:\n",
    "        data[s] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152218, 47), (152218, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].shape, data['train_target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38055, 47), (38055, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test'].shape, data['test_target'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns identified thus far as best for classification (during data prep, select K best)\n",
    "num_attr = ['funded_amnt_q10', 'int_rate_delta', 'annual_inc_q10', 'dti', 'delinq_2yrs', 'inq_last_6mths',\n",
    "            'open_acc', 'revol_bal_log', 'revol_util', 'total_acc', 'collections_12_mths_ex_med',\n",
    "            'acc_now_delinq', 'rev_lim_sqrt', 'tot_cur_bal', 'tot_coll_amt', 'subgrade_p_value',\n",
    "            'lti', 'rbti', 'tbti', 'cr_line_td_log', 'emp_length_val']\n",
    "\n",
    "bin_attr = ['had_delinq', 'had_major_derog', 'had_record', 'verified', 'term_bin']\n",
    "\n",
    "cat_attr = ['purpose', 'home_ownership']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_prep = Pipeline([('custom', my_func.CustomNumAttributes()), # Create custom num attr\n",
    "                     ('select', my_func.DataFrame_Selector(num_attr)), # Select num columns\n",
    "                     ('sc', StandardScaler())]) # Scale data\n",
    "\n",
    "bin_prep = Pipeline([('custom', my_func.CustomBinAttributes()), # Create custom bin attr\n",
    "                     ('select', my_func.DataFrame_Selector(bin_attr))]) # Select binary columns\n",
    "\n",
    "cat_prep = Pipeline([('encode', my_func.DataFrame_DummyEncoder(cat_attr))]) # Select & encode categrocial columns\n",
    "\n",
    "feature_prep = FeatureUnion([('num', num_prep),\n",
    "                             ('bin', bin_prep),\n",
    "                             ('cat', cat_prep)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_full = feature_prep.fit_transform(data['train'])\n",
    "X_test = feature_prep.transform(data['test'])\n",
    "\n",
    "y_train_full = data['train_target']['default']\n",
    "y_test = data['test_target']['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f2_score = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging/Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  5.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 8min 45s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 540 out of 540 | elapsed:  8.7min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10]\n",
    "ms = np.arange(0.1,0.51,0.1)\n",
    "mf = np.arange(0.1,0.91,0.1)\n",
    "\n",
    "lr_best = LogisticRegression(class_weight='balanced',\n",
    "                             C=1e-8)\n",
    "\n",
    "param_grid = {'n_estimators': n,\n",
    "              'max_samples': ms,\n",
    "              'max_features': mf,\n",
    "              'bootstrap': [True, False],\n",
    "              'bootstrap_features': [True, False]}\n",
    "              \n",
    "              \n",
    "bag_lr_gs = GridSearchCV(estimator=BaggingClassifier(lr_best),\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "bag_lr_gs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'bootstrap': False, 'bootstrap_features': False, 'max_features': 0.5, 'max_samples': 0.10000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.5594344980806638\n",
      "Recall = 0.7494031184429233\n",
      "Precision = 0.27779000973640877\n",
      "Specificity = 0.5351119794907921\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'bootstrap': False, 'bootstrap_features': True, 'max_features': 0.30000000000000004, 'max_samples': 0.10000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.557482587232081\n",
      "Recall = 0.7656861372942044\n",
      "Precision = 0.2674615387694146\n",
      "Specificity = 0.4987692009146497\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'bootstrap': True, 'bootstrap_features': False, 'max_features': 0.20000000000000001, 'max_samples': 0.5, 'n_estimators': 10}\n",
      "F2 = 0.5500494241284213\n",
      "Recall = 0.724253997289936\n",
      "Precision = 0.2803979318137403\n",
      "Specificity = 0.5562991781027611\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'bootstrap': False, 'bootstrap_features': True, 'max_features': 0.10000000000000001, 'max_samples': 0.20000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.525022714728165\n",
      "Recall = 0.6831625233646312\n",
      "Precision = 0.2728945770338818\n",
      "Specificity = 0.5652297569307653\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "my_func.gs_score_summary(bag_lr_gs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, performance seems comparable to our best logistic regresion with RFE (whereas this used the full feature set with random feature selection). Let us see if we can further improve performance with different numbers of estimators and random states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed: 48.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 73min 57s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1200 out of 1200 | elapsed: 73.9min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10,20,50,100]\n",
    "rs = np.random.choice(1000,100,replace=False)\n",
    "\n",
    "lr_bag_best = BaggingClassifier(base_estimator=LogisticRegression(class_weight='balanced', C=1e-8),\n",
    "                                max_samples=0.1, max_features=0.5, bootstrap_features=False, bootstrap=False)\n",
    "\n",
    "param_grid = {'n_estimators': n,\n",
    "              'random_state': rs}\n",
    "              \n",
    "              \n",
    "bag_lr_gs_rs = GridSearchCV(estimator=lr_bag_best,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "bag_lr_gs_rs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'n_estimators': 10, 'random_state': 240}\n",
      "F2 = 0.5620017680329654\n",
      "Recall = 0.7611678369267089\n",
      "Precision = 0.274618484809216\n",
      "Specificity = 0.5202412543417095\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'n_estimators': 10, 'random_state': 811}\n",
      "F2 = 0.5594788310698856\n",
      "Recall = 0.7656436830677532\n",
      "Precision = 0.2693680107876574\n",
      "Specificity = 0.5044246093782223\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'n_estimators': 10, 'random_state': 691}\n",
      "F2 = 0.5539260782651078\n",
      "Recall = 0.7255754801240334\n",
      "Precision = 0.28462847274855735\n",
      "Specificity = 0.564792414055423\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'n_estimators': 10, 'random_state': 691}\n",
      "F2 = 0.5539260782651078\n",
      "Recall = 0.7255754801240334\n",
      "Precision = 0.28462847274855735\n",
      "Specificity = 0.564792414055423\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "my_func.gs_score_summary(bag_lr_gs_rs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1e-08, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "         max_samples=0.1, n_estimators=100, n_jobs=1, oob_score=False,\n",
       "         random_state=240, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bag = BaggingClassifier(base_estimator=LogisticRegression(class_weight='balanced', C=1e-8),\n",
    "                           n_estimators=100, max_samples=0.1, max_features=0.5,\n",
    "                           random_state=240)\n",
    "lr_bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall score = 0.751 (+/- 0.003)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(lr_bag, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               52190               46124\n",
      "Actual Positive                5866               17594\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.558334\n",
      "Recall           0.749957\n",
      "Precision (pos)  0.276123\n",
      "Precision (neg)  0.898960\n",
      "Specificity      0.530850\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, lr_bag.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               13083               11547\n",
      "Actual Positive                1454                4360\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.556648\n",
      "Recall           0.749914\n",
      "Precision (pos)  0.274093\n",
      "Precision (neg)  0.899979\n",
      "Specificity      0.531181\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, lr_bag.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our bagging classifier with logisitic regression appears to perform just slightly better than our basic logistic regression model. Perhaps reducing the feature set via RFE can yield better results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=LogisticRegression(class_weight='balanced'), n_features_to_select=28)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_val_rfe = rfe.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  4.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 7min 30s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 600 out of 600 | elapsed:  7.5min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10]\n",
    "ms = np.arange(0.1,.51,0.1)\n",
    "mf = np.arange(0.1,1.01,0.1)\n",
    "\n",
    "lr_best = LogisticRegression(class_weight='balanced',\n",
    "                             C=1e-8)\n",
    "\n",
    "param_grid = {'n_estimators': n,\n",
    "              'max_samples': ms,\n",
    "              'max_features': mf,\n",
    "              'bootstrap': [True, False],\n",
    "              'bootstrap_features': [True, False]}\n",
    "              \n",
    "              \n",
    "bag_lr_gs = GridSearchCV(estimator=BaggingClassifier(lr_best),\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "bag_lr_gs.fit(X_train_rfe, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'bootstrap': True, 'bootstrap_features': True, 'max_features': 0.80000000000000004, 'max_samples': 0.20000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.5631514820400069\n",
      "Recall = 0.7639812516725777\n",
      "Precision = 0.27451060763794466\n",
      "Specificity = 0.5181866302909446\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'bootstrap': False, 'bootstrap_features': True, 'max_features': 0.30000000000000004, 'max_samples': 0.5, 'n_estimators': 10}\n",
      "F2 = 0.5610257708124288\n",
      "Recall = 0.7652600702563471\n",
      "Precision = 0.2714166762710959\n",
      "Specificity = 0.5096629432461715\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'bootstrap': True, 'bootstrap_features': False, 'max_features': 0.5, 'max_samples': 0.40000000000000002, 'n_estimators': 10}\n",
      "F2 = 0.5573478328519754\n",
      "Recall = 0.7400256930609413\n",
      "Precision = 0.2806180777273003\n",
      "Specificity = 0.5469719929706734\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'bootstrap': True, 'bootstrap_features': False, 'max_features': 0.10000000000000001, 'max_samples': 0.10000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.5090942423913063\n",
      "Recall = 0.6551577789672597\n",
      "Precision = 0.26968241938159365\n",
      "Specificity = 0.574648603100275\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "my_func.gs_score_summary(bag_lr_gs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  2.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4min 58s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:  5.0min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10]\n",
    "rs = np.random.choice(1000,100,replace=False)\n",
    "\n",
    "lr_bag_best = BaggingClassifier(base_estimator=LogisticRegression(class_weight='balanced', C=1e-8),\n",
    "                                max_samples=0.2, max_features=0.8, bootstrap_features=True, bootstrap=True)\n",
    "\n",
    "param_grid = {'n_estimators': n,\n",
    "              'random_state': rs}\n",
    "              \n",
    "              \n",
    "bag_lr_gs_rs = GridSearchCV(estimator=lr_bag_best,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "bag_lr_gs_rs.fit(X_train_rfe, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'n_estimators': 10, 'random_state': 912}\n",
      "F2 = 0.5643143143418878\n",
      "Recall = 0.7645353692179848\n",
      "Precision = 0.27561135941914283\n",
      "Specificity = 0.5204752235569098\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'n_estimators': 10, 'random_state': 981}\n",
      "F2 = 0.5640853358115085\n",
      "Recall = 0.7709718449551656\n",
      "Precision = 0.27206298534193146\n",
      "Specificity = 0.5077608518621809\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'n_estimators': 10, 'random_state': 600}\n",
      "F2 = 0.5544857778811442\n",
      "Recall = 0.7259164811910807\n",
      "Precision = 0.2851517186899203\n",
      "Specificity = 0.5657180147649826\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'n_estimators': 10, 'random_state': 600}\n",
      "F2 = 0.5544857778811442\n",
      "Recall = 0.7259164811910807\n",
      "Precision = 0.2851517186899203\n",
      "Specificity = 0.5657180147649826\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "my_func.gs_score_summary(bag_lr_gs_rs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1e-08, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=True, max_features=0.8,\n",
       "         max_samples=0.2, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=912, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bag_best = BaggingClassifier(base_estimator=LogisticRegression(class_weight='balanced', C=1e-8),\n",
    "                                max_samples=0.2, max_features=0.8, bootstrap_features=True, bootstrap=True,\n",
    "                                n_estimators=10, random_state=912)\n",
    "\n",
    "lr_bag_best.fit(X_train_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV score = 0.760 (+/- 0.006)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(lr_bag_best, X_train, y_train, cv=5, scoring='recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               51714               46600\n",
      "Actual Positive                5599               17861\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.564147\n",
      "Recall           0.761338\n",
      "Precision (pos)  0.277082\n",
      "Precision (neg)  0.902308\n",
      "Specificity      0.526009\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, lr_bag_best.predict(X_train_rfe));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               12977               11653\n",
      "Actual Positive                1382                4432\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.563280\n",
      "Recall           0.762298\n",
      "Precision (pos)  0.275536\n",
      "Precision (neg)  0.903754\n",
      "Specificity      0.526878\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, lr_bag_best.predict(X_val_rfe));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bagging classifier is able to achieve slightly better results in recall/F2 than the individual logistic regression model which scored in the 0.74 recall range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4min 58s \n"
     ]
    }
   ],
   "source": [
    "svc_rfe = RFE(estimator=LinearSVC(class_weight='balanced', dual=False), n_features_to_select=31)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "svc_rfe.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_rfe = svc_rfe.transform(X_train)\n",
    "X_val_rfe = svc_rfe.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed: 12.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 19min 21s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 540 out of 540 | elapsed: 19.3min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10]\n",
    "ms = np.arange(0.1,0.51,0.1)\n",
    "mf = np.arange(0.1,0.91,0.1)\n",
    "\n",
    "lsvc_best = LinearSVC(class_weight='balanced',\n",
    "                             dual=False,\n",
    "                             C=1e-7)\n",
    "\n",
    "param_grid = {'n_estimators': n,\n",
    "              'max_samples': ms,\n",
    "              'max_features': mf,\n",
    "              'bootstrap': [True, False],\n",
    "              'bootstrap_features': [True, False]}\n",
    "              \n",
    "              \n",
    "bag_lsvc_gs = GridSearchCV(estimator=BaggingClassifier(lsvc_best),\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "bag_lsvc_gs.fit(X_train_rfe, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'bootstrap': False, 'bootstrap_features': False, 'max_features': 0.80000000000000004, 'max_samples': 0.20000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.5592059894837366\n",
      "Recall = 0.7416453509933731\n",
      "Precision = 0.28186230223931485\n",
      "Specificity = 0.5490977904537727\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'bootstrap': False, 'bootstrap_features': False, 'max_features': 0.90000000000000002, 'max_samples': 0.40000000000000002, 'n_estimators': 10}\n",
      "F2 = 0.5590838657712465\n",
      "Recall = 0.7446291213562906\n",
      "Precision = 0.2800350213979244\n",
      "Specificity = 0.5430864350629773\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'bootstrap': False, 'bootstrap_features': False, 'max_features': 0.30000000000000004, 'max_samples': 0.20000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.5407294410959187\n",
      "Recall = 0.6916881759119666\n",
      "Precision = 0.2891902118148557\n",
      "Specificity = 0.5934760763915768\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'bootstrap': True, 'bootstrap_features': False, 'max_features': 0.10000000000000001, 'max_samples': 0.40000000000000002, 'n_estimators': 10}\n",
      "F2 = 0.38761231912158894\n",
      "Recall = 0.4553703147296004\n",
      "Precision = 0.27719081633582277\n",
      "Specificity = 0.7060030806190857\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "my_func.gs_score_summary(bag_lsvc_gs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  6.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 11min 50s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed: 11.8min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10]\n",
    "rs = np.random.choice(1000,100,replace=False)\n",
    "\n",
    "lsvc_best = LinearSVC(class_weight='balanced', dual=False, C=1e-7)\n",
    "\n",
    "lsvc_bag_best = BaggingClassifier(base_estimator=lsvc_best,\n",
    "                                max_samples=0.2, max_features=0.8, bootstrap_features=False, bootstrap=False)\n",
    "\n",
    "param_grid = {'n_estimators': n,\n",
    "              'random_state': rs}\n",
    "              \n",
    "              \n",
    "bag_lsvc_gs_rs = GridSearchCV(estimator=lsvc_bag_best,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "bag_lsvc_gs_rs.fit(X_train_rfe, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'n_estimators': 10, 'random_state': 521}\n",
      "F2 = 0.5599233896500295\n",
      "Recall = 0.7497015991259982\n",
      "Precision = 0.27821638078034466\n",
      "Specificity = 0.5358748535994515\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'n_estimators': 10, 'random_state': 521}\n",
      "F2 = 0.5599233896500295\n",
      "Recall = 0.7497015991259982\n",
      "Precision = 0.27821638078034466\n",
      "Specificity = 0.5358748535994515\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'n_estimators': 10, 'random_state': 892}\n",
      "F2 = 0.5554190019646637\n",
      "Recall = 0.7275788632306451\n",
      "Precision = 0.28534587052767163\n",
      "Specificity = 0.565168746758098\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'n_estimators': 10, 'random_state': 797}\n",
      "F2 = 0.5482968582517055\n",
      "Recall = 0.7166666789180595\n",
      "Precision = 0.2826672142401392\n",
      "Specificity = 0.5660129816558485\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "my_func.gs_score_summary(bag_lsvc_gs_rs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LinearSVC(C=1e-07, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "         bootstrap=False, bootstrap_features=False, max_features=0.8,\n",
       "         max_samples=0.2, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=521, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_best = LinearSVC(class_weight='balanced', dual=False, C=1e-7)\n",
    "lsvc_bag = BaggingClassifier(base_estimator=lsvc_best, n_estimators=10, max_samples=0.2, max_features=0.8,\n",
    "                             bootstrap_features=False, bootstrap=False,\n",
    "                             random_state=521)\n",
    "\n",
    "lsvc_bag.fit(X_train_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV score = 0.749 (+/- 0.003)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(lsvc_bag, X_train_rfe, y_train, cv=5, scoring='recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               52897               45417\n",
      "Actual Positive                5893               17567\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.560086\n",
      "Recall           0.748806\n",
      "Precision (pos)  0.278912\n",
      "Precision (neg)  0.899762\n",
      "Specificity      0.538041\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, lsvc_bag.predict(X_train_rfe));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               13314               11316\n",
      "Actual Positive                1460                4354\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.559266\n",
      "Recall           0.748882\n",
      "Precision (pos)  0.277856\n",
      "Precision (neg)  0.901178\n",
      "Specificity      0.540560\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, lsvc_bag.predict(X_val_rfe));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baggig classifier shows an improvement in recall on the magnitude of 0.001 over the singular linear SVC model. This slight increase, however, does not seem to have come at the expense of specificity or precision which also see similar improvement. Consequently, whilst these improvements are very minimal this bagging classifier does provide a slightly more robust solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging our decision tree classifier is essentially constructing a rough random forest model, however we gain the added ability to reduce the number of samples used in each tree. Using what we had seen in previous grid searches for random forest as the best performing parameters and value ranges, we will repeat said process with a bagging classifier of 10 random forest classifiers. Note, however, that the process of feature selection has been moved from the random forest classifier up to the bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 640 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed: 21.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 30min 49s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1920 out of 1920 | elapsed: 30.8min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10, 15, 20]\n",
    "ms = np.arange(0.2,0.51,0.1)\n",
    "mf = np.arange(0.2,0.91,0.1)\n",
    "md = np.arange(1,11,1)\n",
    "\n",
    "dtc_bag = BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced'))\n",
    "\n",
    "param_grid = {'base_estimator__max_depth': md,\n",
    "              'n_estimators': n,\n",
    "              'max_samples': ms,\n",
    "              'max_features': mf,\n",
    "              'bootstrap_features': [True, False]}\n",
    "              \n",
    "              \n",
    "dtc_bag_gs = GridSearchCV(estimator=dtc_bag,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "dtc_bag_gs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'base_estimator__max_depth': 5, 'bootstrap_features': True, 'max_features': 0.90000000000000013, 'max_samples': 0.40000000000000008, 'n_estimators': 10}\n",
      "F2 = 0.53678209149419\n",
      "Recall = 0.663938590572608\n",
      "Precision = 0.3039521928054217\n",
      "Specificity = 0.6371829059552738\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'base_estimator__max_depth': 1, 'bootstrap_features': False, 'max_features': 0.90000000000000013, 'max_samples': 0.40000000000000008, 'n_estimators': 10}\n",
      "F2 = 0.5345618793721649\n",
      "Recall = 0.7043904787859713\n",
      "Precision = 0.2723405391468542\n",
      "Specificity = 0.5503896015056183\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'base_estimator__max_depth': 10, 'bootstrap_features': False, 'max_features': 0.90000000000000013, 'max_samples': 0.20000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.4560456917741673\n",
      "Recall = 0.504092054809343\n",
      "Precision = 0.33032007452125606\n",
      "Specificity = 0.7561283226879555\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'base_estimator__max_depth': 10, 'bootstrap_features': True, 'max_features': 0.70000000000000018, 'max_samples': 0.20000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.4197890094651247\n",
      "Recall = 0.45417740851286414\n",
      "Precision = 0.32258798525540455\n",
      "Specificity = 0.7724128924487508\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "my_func.gs_score_summary(dtc_bag_gs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed: 49.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 75min 29s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1200 out of 1200 | elapsed: 75.5min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10,20,50,100]\n",
    "rs = np.random.choice(1000,100,replace=False)\n",
    "\n",
    "dtc_best = DecisionTreeClassifier(class_weight='balanced', max_depth=1)\n",
    "\n",
    "dtc_bag_best = BaggingClassifier(base_estimator=dtc_best,\n",
    "                                 bootstrap=False, bootstrap_features=False, \n",
    "                                 max_features=0.7, max_samples=0.2)\n",
    "\n",
    "param_grid = {'n_estimators': n,\n",
    "              'random_state': rs}\n",
    "              \n",
    "              \n",
    "bag_dtc_gs_rs = GridSearchCV(estimator=dtc_bag_best,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "bag_dtc_gs_rs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'n_estimators': 10, 'random_state': 321}\n",
      "F2 = 0.5388335922760672\n",
      "Recall = 0.7209717577952568\n",
      "Precision = 0.2680661195492892\n",
      "Specificity = 0.5302500091793592\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'n_estimators': 10, 'random_state': 321}\n",
      "F2 = 0.5388335922760672\n",
      "Recall = 0.7209717577952568\n",
      "Precision = 0.2680661195492892\n",
      "Specificity = 0.5302500091793592\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'n_estimators': 20, 'random_state': 90}\n",
      "F2 = 0.45287796804654684\n",
      "Recall = 0.5168797008856748\n",
      "Precision = 0.3029689797666358\n",
      "Specificity = 0.7161950304089691\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'n_estimators': 20, 'random_state': 90}\n",
      "F2 = 0.45287796804654684\n",
      "Recall = 0.5168797008856748\n",
      "Precision = 0.3029689797666358\n",
      "Specificity = 0.7161950304089691\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "my_func.gs_score_summary(bag_dtc_gs_rs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_bag_best = BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', max_depth=1),\n",
    "                            bootstrap=False, bootstrap_features=False, \n",
    "                            max_features=0.7, max_samples=0.2,\n",
    "                            random_state=321)\n",
    "\n",
    "dtc_bag_best.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.526 (+/- 0.007)\n",
      "Mean recall score = 0.679 (+/- 0.020)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(dtc_bag_best, X_train, y_train, cv=5, scoring=f2_score), 'f2')\n",
    "my_func.print_cvs(cross_val_score(dtc_bag_best, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               58462               39852\n",
      "Actual Positive                7996               15464\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.518383\n",
      "Recall           0.659165\n",
      "Precision (pos)  0.279557\n",
      "Precision (neg)  0.879683\n",
      "Specificity      0.594646\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, dtc_bag_best.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               14564               10066\n",
      "Actual Positive                2017                3797\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.511463\n",
      "Recall           0.653079\n",
      "Precision (pos)  0.273895\n",
      "Precision (neg)  0.878355\n",
      "Specificity      0.591311\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, dtc_bag_best.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately this baggig classifier performs singificantly worse than our singular optimized decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather surprisingly, our random forest classifier model fared signficantly worse than our individual decision tree. Perhaps bagging a number of random forest classifiers which are fit on varying subsamples can yield improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 750 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed: 41.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 47min 5s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 2250 out of 2250 | elapsed: 47.1min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10]\n",
    "ms = np.arange(0.1,0.51,0.1)\n",
    "mf = np.arange(0.1,0.51,0.1)\n",
    "md = np.arange(1,6,1)\n",
    "msl = np.arange(0.05,0.11,0.01)\n",
    "\n",
    "rfc_bag = BaggingClassifier(base_estimator=RandomForestClassifier(class_weight='balanced'))\n",
    "\n",
    "param_grid = {'base_estimator__max_depth': md,\n",
    "              'base_estimator__min_samples_leaf': msl,\n",
    "              'n_estimators': n,\n",
    "              'max_samples': ms,\n",
    "              'max_features': mf}\n",
    "              \n",
    "              \n",
    "rfc_bag_gs = GridSearchCV(estimator=rfc_bag,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "rfc_bag_gs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'base_estimator__max_depth': 1, 'base_estimator__min_samples_leaf': 0.050000000000000003, 'max_features': 0.10000000000000001, 'max_samples': 0.10000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.5440277532818429\n",
      "Recall = 1.0\n",
      "Precision = 0.19265196183093272\n",
      "Specificity = 0.0\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'base_estimator__max_depth': 1, 'base_estimator__min_samples_leaf': 0.050000000000000003, 'max_features': 0.10000000000000001, 'max_samples': 0.10000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.5440277532818429\n",
      "Recall = 1.0\n",
      "Precision = 0.19265196183093272\n",
      "Specificity = 0.0\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'base_estimator__max_depth': 5, 'base_estimator__min_samples_leaf': 0.050000000000000003, 'max_features': 0.5, 'max_samples': 0.30000000000000004, 'n_estimators': 10}\n",
      "F2 = 0.5100696036621141\n",
      "Recall = 0.6218243738757685\n",
      "Precision = 0.29682392905454735\n",
      "Specificity = 0.6484834380012143\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'base_estimator__max_depth': 1, 'base_estimator__min_samples_leaf': 0.060000000000000005, 'max_features': 0.10000000000000001, 'max_samples': 0.20000000000000001, 'n_estimators': 10}\n",
      "F2 = 0.0\n",
      "Recall = 0.0\n",
      "Precision = 0.0\n",
      "Specificity = 1.0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "rfc_gs_summary = my_func.gs_score_summary(rfc_bag_gs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F2</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>base_estimator__max_depth</th>\n",
       "      <th>base_estimator__min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.531220</td>\n",
       "      <td>0.284090</td>\n",
       "      <td>0.679326</td>\n",
       "      <td>0.591208</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>0.530213</td>\n",
       "      <td>0.286292</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.599162</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.530193</td>\n",
       "      <td>0.286227</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.599030</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0.529682</td>\n",
       "      <td>0.291104</td>\n",
       "      <td>0.666624</td>\n",
       "      <td>0.612425</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.529238</td>\n",
       "      <td>0.283078</td>\n",
       "      <td>0.676257</td>\n",
       "      <td>0.591289</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.529226</td>\n",
       "      <td>0.286958</td>\n",
       "      <td>0.670887</td>\n",
       "      <td>0.602142</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.529041</td>\n",
       "      <td>0.282727</td>\n",
       "      <td>0.676556</td>\n",
       "      <td>0.590231</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.528292</td>\n",
       "      <td>0.289226</td>\n",
       "      <td>0.666113</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.528053</td>\n",
       "      <td>0.287137</td>\n",
       "      <td>0.668286</td>\n",
       "      <td>0.604034</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.527554</td>\n",
       "      <td>0.287073</td>\n",
       "      <td>0.667349</td>\n",
       "      <td>0.604471</td>\n",
       "      <td>3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           F2  precision    recall  specificity  base_estimator__max_depth  \\\n",
       "7    0.531220   0.284090  0.679326     0.591208                          1   \n",
       "624  0.530213   0.286292  0.673785     0.599162                          5   \n",
       "49   0.530193   0.286227  0.673785     0.599030                          1   \n",
       "619  0.529682   0.291104  0.666624     0.612425                          5   \n",
       "439  0.529238   0.283078  0.676257     0.591289                          3   \n",
       "322  0.529226   0.286958  0.670887     0.602142                          3   \n",
       "512  0.529041   0.282727  0.676556     0.590231                          4   \n",
       "468  0.528292   0.289226  0.666113     0.609272                          4   \n",
       "604  0.528053   0.287137  0.668286     0.604034                          5   \n",
       "369  0.527554   0.287073  0.667349     0.604471                          3   \n",
       "\n",
       "     base_estimator__min_samples_leaf  max_features  max_samples  n_estimators  \n",
       "7                                0.05           0.2          0.3            10  \n",
       "624                              0.05           0.5          0.5            10  \n",
       "49                               0.06           0.5          0.5            10  \n",
       "619                              0.05           0.4          0.5            10  \n",
       "439                              0.10           0.3          0.5            10  \n",
       "322                              0.05           0.5          0.3            10  \n",
       "512                              0.07           0.3          0.3            10  \n",
       "468                              0.05           0.4          0.4            10  \n",
       "604                              0.05           0.1          0.5            10  \n",
       "369                              0.07           0.4          0.5            10  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_gs_summary[rfc_gs_summary['specificity'] > 0.5].sort_values('F2', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed with the 2nd highest model with a max depth of 5 to avoid overlap and redundancy with our previous decision tree bagging classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating our grid search on the random state to ensure reporucible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 6min 8s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:  6.1min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "n = [10]\n",
    "rs = np.random.choice(1000,100,replace=False)\n",
    "\n",
    "rfc_bag_test = BaggingClassifier(base_estimator=RandomForestClassifier(class_weight='balanced', max_depth=5, min_samples_leaf=0.05),\n",
    "                                 max_features=0.2, max_samples=0.3)\n",
    "\n",
    "param_grid = {'n_estimators': n,\n",
    "              'random_state': rs}\n",
    "              \n",
    "              \n",
    "rfc_bag_gs_rs = GridSearchCV(estimator=rfc_bag_test,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "rfc_bag_gs_rs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'n_estimators': 10, 'random_state': 748}\n",
      "F2 = 0.5317842051103716\n",
      "Recall = 0.6888743600204933\n",
      "Precision = 0.27863735765936076\n",
      "Specificity = 0.5739466750648292\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'n_estimators': 10, 'random_state': 653}\n",
      "F2 = 0.5282411968708435\n",
      "Recall = 0.6909633751122629\n",
      "Precision = 0.2721392481442231\n",
      "Specificity = 0.558882784002206\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'n_estimators': 10, 'random_state': 340}\n",
      "F2 = 0.5021351468833133\n",
      "Recall = 0.6067347327448268\n",
      "Precision = 0.2973531546797534\n",
      "Specificity = 0.6578004925213042\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'n_estimators': 10, 'random_state': 577}\n",
      "F2 = 0.4716140517934157\n",
      "Recall = 0.553751240663546\n",
      "Precision = 0.2966131389379102\n",
      "Specificity = 0.6863417545965096\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "rfc_gs_rs_summary = my_func.gs_score_summary(rfc_bag_gs_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_bag_best = BaggingClassifier(base_estimator=RandomForestClassifier(class_weight='balanced', max_depth=5, min_samples_leaf=0.05),\n",
    "                                 max_features=0.2, max_samples=0.3,\n",
    "                                 n_estimators=10, random_state=748)\n",
    "\n",
    "rfc_bag_best.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.526 (+/- 0.013)\n",
      "Mean recall score = 0.674 (+/- 0.033)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(rfc_bag_best, X_train, y_train, cv=5, scoring=f2_score), 'f2')\n",
    "my_func.print_cvs(cross_val_score(rfc_bag_best, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               53822               44492\n",
      "Actual Positive                6685               16775\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.540756\n",
      "Recall           0.715047\n",
      "Precision (pos)  0.273802\n",
      "Precision (neg)  0.889517\n",
      "Specificity      0.547450\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, rfc_bag_best.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               13545               11085\n",
      "Actual Positive                1707                4107\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.534098\n",
      "Recall           0.706398\n",
      "Precision (pos)  0.270340\n",
      "Precision (neg)  0.888080\n",
      "Specificity      0.549939\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, rfc_bag_best.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these results are not awful, we are unfortunately unable to exceed the performance of our singular random forest classifier. It is very possible that we simply have not explored the optimal hyperparameter combinations for both the bagging classifier and the base random forest estimators. The number of estimators has been kept at 10 throughout our optimization, and the random forest parameters tuning was constrained to be somewhat basic, but exploring all of these possible combination in-depth would come at an unreasonable time cost considering this reduced set of tuning already took 47 minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes has not been explored yet, as it was established during the MVP analysis that this model performed very poorly in comporison with other benchmarks and models. However, it is possible that in conjunction with bagging and smaller sample sizes that these results reach more acceptable levels. Whilst it is unlikely it will ever be at a level to perform reliable individually, perhaps it can be incorporated in an ensemble with other models to yield optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will take a look at the basic Gaussian NB model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb_basic = GaussianNB()\n",
    "gnb_basic.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.410 (+/- 0.030)\n",
      "Mean recall score = 0.438 (+/- 0.046)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(gnb_basic, X_train, y_train, cv=5, scoring=f2_score), 'f2')\n",
    "my_func.print_cvs(cross_val_score(gnb_basic, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               78143               20171\n",
      "Actual Positive               13335               10125\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.407819\n",
      "Recall           0.431586\n",
      "Precision (pos)  0.334203\n",
      "Precision (neg)  0.854227\n",
      "Specificity      0.794831\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, gnb_basic.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               19676                4954\n",
      "Actual Positive                3362                2452\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.399843\n",
      "Recall           0.421741\n",
      "Precision (pos)  0.331083\n",
      "Precision (neg)  0.854067\n",
      "Specificity      0.798863\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, gnb_basic.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will see if there is any immediate potential in reducing the number of features via Select K Best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "Done 3 tasks | elapsed: 3.04s \n",
      "Done 33 tasks | elapsed: 32.18s \n",
      "Done 63 tasks | elapsed: 1min 3s \n",
      "Done 93 tasks | elapsed: 1min 33s \n",
      "Done 120 out of 120 | elapsed: 2min 1s  finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d01dbf6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtwAAAHwCAYAAACVL7i5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d01dbfa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gnb_skb_results = my_func.plot_skb(GaussianNB(), X_train, y_train, k_range=np.arange(1,41,1), scoring='f2', n_jobs=3, verbose=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not seem to be much benefit achievable through SelectKBest feature selection. We will proceed with the grid search using a bagging classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  8.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 25min 40s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed: 25.7min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision': 'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "gnb_test = GaussianNB()\n",
    "\n",
    "gnb_bag_test = BaggingClassifier(base_estimator=gnb_test)\n",
    "\n",
    "n = [10,20,50,100]\n",
    "ms = np.arange(0.1,0.51,0.1)\n",
    "mf = np.arange(0.1,.51,0.1)\n",
    "\n",
    "param_grid = {'n_estimators': n,\n",
    "              'max_samples': ms,\n",
    "              'max_features': mf}\n",
    "              \n",
    "gnb_bag_gs = GridSearchCV(estimator=gnb_bag_test,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "gnb_bag_gs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'max_features': 0.5, 'max_samples': 0.20000000000000001, 'n_estimators': 50}\n",
      "F2 = 0.5510003394562453\n",
      "Recall = 0.9574171076713027\n",
      "Precision = 0.20536898343726204\n",
      "Specificity = 0.10795019583451829\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'max_features': 0.30000000000000004, 'max_samples': 0.20000000000000001, 'n_estimators': 20}\n",
      "F2 = 0.546014864433759\n",
      "Recall = 0.9874254893041771\n",
      "Precision = 0.19587196876445004\n",
      "Specificity = 0.032375909867361975\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'max_features': 0.10000000000000001, 'max_samples': 0.20000000000000001, 'n_estimators': 50}\n",
      "F2 = 0.00010656139573189167\n",
      "Recall = 8.525184194090289e-05\n",
      "Precision = 0.6666694039778607\n",
      "Specificity = 1.0\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'max_features': 0.10000000000000001, 'max_samples': 0.10000000000000001, 'n_estimators': 100}\n",
      "F2 = 0.0\n",
      "Recall = 0.0\n",
      "Precision = 0.0\n",
      "Specificity = 1.0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "gnb_gs_summary = my_func.gs_score_summary(gnb_bag_gs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results for F2 and recall unfortunately come at an unacceptable cost to precision and specificity. We will explore the grid search results with a specificity over 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F2</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.504645</td>\n",
       "      <td>0.287719</td>\n",
       "      <td>0.641391</td>\n",
       "      <td>0.606048</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.500690</td>\n",
       "      <td>0.288401</td>\n",
       "      <td>0.638748</td>\n",
       "      <td>0.605957</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.487782</td>\n",
       "      <td>0.297715</td>\n",
       "      <td>0.603623</td>\n",
       "      <td>0.639746</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.487508</td>\n",
       "      <td>0.277554</td>\n",
       "      <td>0.667777</td>\n",
       "      <td>0.512013</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.485914</td>\n",
       "      <td>0.302557</td>\n",
       "      <td>0.572975</td>\n",
       "      <td>0.684704</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.306993</td>\n",
       "      <td>0.551876</td>\n",
       "      <td>0.702311</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.450914</td>\n",
       "      <td>0.296524</td>\n",
       "      <td>0.574598</td>\n",
       "      <td>0.621998</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.449124</td>\n",
       "      <td>0.307544</td>\n",
       "      <td>0.544034</td>\n",
       "      <td>0.683514</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.446966</td>\n",
       "      <td>0.297594</td>\n",
       "      <td>0.596462</td>\n",
       "      <td>0.590292</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.431746</td>\n",
       "      <td>0.302884</td>\n",
       "      <td>0.541516</td>\n",
       "      <td>0.650680</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F2  precision    recall  specificity  max_features  max_samples  \\\n",
       "46  0.504645   0.287719  0.641391     0.606048           0.3          0.2   \n",
       "42  0.500690   0.288401  0.638748     0.605957           0.3          0.1   \n",
       "43  0.487782   0.297715  0.603623     0.639746           0.3          0.1   \n",
       "41  0.487508   0.277554  0.667777     0.512013           0.3          0.1   \n",
       "74  0.485914   0.302557  0.572975     0.684704           0.4          0.4   \n",
       "89  0.475716   0.306993  0.551876     0.702311           0.5          0.3   \n",
       "69  0.450914   0.296524  0.574598     0.621998           0.4          0.3   \n",
       "71  0.449124   0.307544  0.544034     0.683514           0.4          0.3   \n",
       "49  0.446966   0.297594  0.596462     0.590292           0.3          0.3   \n",
       "75  0.431746   0.302884  0.541516     0.650680           0.4          0.4   \n",
       "\n",
       "    n_estimators  \n",
       "46            50  \n",
       "42            50  \n",
       "43           100  \n",
       "41            20  \n",
       "74            50  \n",
       "89            20  \n",
       "69            20  \n",
       "71           100  \n",
       "49            20  \n",
       "75           100  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_gs_summary[gnb_gs_summary['specificity'] > 0.5].sort_values('F2', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with random selections of features and samples, we will also try to contrain our random state for reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 14.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 27min 50s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed: 27.8min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision': 'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "gnb_bag_test = BaggingClassifier(base_estimator=GaussianNB(),\n",
    "                             max_features=0.3, max_samples=0.2,\n",
    "                             n_estimators=50)\n",
    "\n",
    "rs = np.random.choice(1000,100,replace=False)\n",
    "\n",
    "param_grid = {'random_state': rs}\n",
    "              \n",
    "gnb_bag_gs = GridSearchCV(estimator=gnb_bag_test,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "gnb_bag_gs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'random_state': 475}\n",
      "F2 = 0.5575548512891193\n",
      "Recall = 0.8846553835819378\n",
      "Precision = 0.228668375884531\n",
      "Specificity = 0.27144692409855553\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'random_state': 684}\n",
      "F2 = 0.5517213336235701\n",
      "Recall = 0.9456950607886808\n",
      "Precision = 0.20863756225424387\n",
      "Specificity = 0.1330127407209551\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'random_state': 301}\n",
      "F2 = 0.15585431243158449\n",
      "Recall = 0.13699969739759837\n",
      "Precision = 0.4026915309085073\n",
      "Specificity = 0.9500580389871074\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'random_state': 301}\n",
      "F2 = 0.15585431243158449\n",
      "Recall = 0.13699969739759837\n",
      "Precision = 0.4026915309085073\n",
      "Specificity = 0.9500580389871074\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "my_func.gs_score_summary(gnb_bag_gs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'random_state': 475}\n",
      "F2 = 0.5575548512891193\n",
      "Recall = 0.8846553835819378\n",
      "Precision = 0.228668375884531\n",
      "Specificity = 0.27144692409855553\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'random_state': 684}\n",
      "F2 = 0.5517213336235701\n",
      "Recall = 0.9456950607886808\n",
      "Precision = 0.20863756225424387\n",
      "Specificity = 0.1330127407209551\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'random_state': 301}\n",
      "F2 = 0.15585431243158449\n",
      "Recall = 0.13699969739759837\n",
      "Precision = 0.4026915309085073\n",
      "Specificity = 0.9500580389871074\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'random_state': 301}\n",
      "F2 = 0.15585431243158449\n",
      "Recall = 0.13699969739759837\n",
      "Precision = 0.4026915309085073\n",
      "Specificity = 0.9500580389871074\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "gnb_bag_gs_summary = my_func.gs_score_summary(gnb_bag_gs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F2</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.536014</td>\n",
       "      <td>0.274005</td>\n",
       "      <td>0.715687</td>\n",
       "      <td>0.536679</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.269339</td>\n",
       "      <td>0.728687</td>\n",
       "      <td>0.510609</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.523996</td>\n",
       "      <td>0.280850</td>\n",
       "      <td>0.678516</td>\n",
       "      <td>0.576530</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.520328</td>\n",
       "      <td>0.280751</td>\n",
       "      <td>0.675575</td>\n",
       "      <td>0.573326</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.517219</td>\n",
       "      <td>0.279672</td>\n",
       "      <td>0.670291</td>\n",
       "      <td>0.576449</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.515228</td>\n",
       "      <td>0.287085</td>\n",
       "      <td>0.647997</td>\n",
       "      <td>0.611358</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.513171</td>\n",
       "      <td>0.275006</td>\n",
       "      <td>0.676770</td>\n",
       "      <td>0.556828</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.512225</td>\n",
       "      <td>0.284429</td>\n",
       "      <td>0.654474</td>\n",
       "      <td>0.598328</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.511497</td>\n",
       "      <td>0.273003</td>\n",
       "      <td>0.691519</td>\n",
       "      <td>0.531308</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.502922</td>\n",
       "      <td>0.281908</td>\n",
       "      <td>0.669691</td>\n",
       "      <td>0.562371</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F2  precision    recall  specificity  random_state\n",
       "64  0.536014   0.274005  0.715687     0.536679           540\n",
       "0   0.535088   0.269339  0.728687     0.510609           807\n",
       "52  0.523996   0.280850  0.678516     0.576530           619\n",
       "14  0.520328   0.280751  0.675575     0.573326           997\n",
       "13  0.517219   0.279672  0.670291     0.576449           507\n",
       "12  0.515228   0.287085  0.647997     0.611358            41\n",
       "33  0.513171   0.275006  0.676770     0.556828           144\n",
       "40  0.512225   0.284429  0.654474     0.598328            39\n",
       "61  0.511497   0.273003  0.691519     0.531308           363\n",
       "55  0.502922   0.281908  0.669691     0.562371           792"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_bag_gs_summary[gnb_bag_gs_summary['specificity'] > 0.5].sort_values('F2', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3.50s \n"
     ]
    }
   ],
   "source": [
    "gnb_best = BaggingClassifier(base_estimator=GaussianNB(),\n",
    "                             max_features=0.3, max_samples=0.2,\n",
    "                             n_estimators=50, random_state=540)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "gnb_best.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.506 (+/- 0.037)\n",
      "Mean recall score = 0.663 (+/- 0.158)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(gnb_best, X_train, y_train, cv=5, scoring=f2_score), 'f2')\n",
    "my_func.print_cvs(cross_val_score(gnb_best, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               90757                7557\n",
      "Actual Positive               18847                4613\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.217574\n",
      "Recall           0.196633\n",
      "Precision (pos)  0.379047\n",
      "Precision (neg)  0.828045\n",
      "Specificity      0.923134\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, gnb_best.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               22816                1814\n",
      "Actual Positive                4723                1091\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.208516\n",
      "Recall           0.187650\n",
      "Precision (pos)  0.375559\n",
      "Precision (neg)  0.828498\n",
      "Specificity      0.926350\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, gnb_best.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem our model has been severely overfitted, likely as a result of the random state being optimized for the specific size of the folds in our cross validation versus our full training/validation set. Consequently, it may be best to discard to the random state parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3.49s \n"
     ]
    }
   ],
   "source": [
    "gnb_best = BaggingClassifier(base_estimator=GaussianNB(),\n",
    "                             max_features=0.3, max_samples=0.2,\n",
    "                             n_estimators=50)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "gnb_best.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.459 (+/- 0.074)\n",
      "Mean recall score = 0.558 (+/- 0.370)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(gnb_best, X_train, y_train, cv=5, scoring=f2_score), 'f2')\n",
    "my_func.print_cvs(cross_val_score(gnb_best, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               78506               19808\n",
      "Actual Positive               13429               10031\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.405526\n",
      "Recall           0.427579\n",
      "Precision (pos)  0.336171\n",
      "Precision (neg)  0.853929\n",
      "Specificity      0.798523\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, gnb_best.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               19822                4808\n",
      "Actual Positive                3439                2375\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.390125\n",
      "Recall           0.408497\n",
      "Precision (pos)  0.330642\n",
      "Precision (neg)  0.852156\n",
      "Specificity      0.804791\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, gnb_best.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst we see some signficiant improvements in F2/recall over our previously fixed random state model, it is important to note the huge variance of 0.37 in our cross validation scores. Depending on the configuration of th efit, we could potentially see recall in range of 0.2 to 0.8. As seen earlier, fixing random state for consistency simply results in overfitting the specific sample size, which then falls apart when we use the full training set. Consequently, this model is of little use individually compared to the performance of other classifiers. However, as mentioned earlier it may still be of use in ultimate ensemble classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hard Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_best = Pipeline([('rfe', RFE(estimator=LogisticRegression(class_weight='balanced'), n_features_to_select=28)),\n",
    "                    ('estimator', LogisticRegression(class_weight='balanced', C=1e-8))])\n",
    "\n",
    "lr_bag_best = Pipeline([('rfe', RFE(estimator=LogisticRegression(class_weight='balanced'), n_features_to_select=28)),\n",
    "                    ('estimator', BaggingClassifier(base_estimator=LogisticRegression(class_weight='balanced', C=1e-8),\n",
    "                                                   max_samples=0.2, max_features=0.8, bootstrap_features=True, bootstrap=True,\n",
    "                                                   n_estimators=10, random_state=998))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_best = Pipeline([('rfe', RFE(estimator=LinearSVC(class_weight='balanced', dual=False), n_features_to_select=31)),\n",
    "                      ('estimator', LinearSVC(class_weight='balanced', dual=False, C=1e-7, ))])\n",
    "\n",
    "lsvc_bag_best = BaggingClassifier(base_estimator=LinearSVC(class_weight='balanced', dual=False, C=1e-7),\n",
    "                             n_estimators=10, max_samples=0.2, max_features=0.8,\n",
    "                             bootstrap_features=False, bootstrap=False,\n",
    "                             random_state=521)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_best = DecisionTreeClassifier(class_weight='balanced', max_depth=4, max_features=0.4, random_state=356)\n",
    "\n",
    "\n",
    "dtc_bag_best = BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', max_depth=1),\n",
    "                            bootstrap=False, bootstrap_features=False, \n",
    "                            max_features=0.7, max_samples=0.2,\n",
    "                            random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_best = RandomForestClassifier(class_weight='balanced', max_features=0.5, min_samples_leaf=.095,\n",
    "                                  n_estimators=10, random_state=808)\n",
    "\n",
    "\n",
    "rfc_bag_best = BaggingClassifier(base_estimator=RandomForestClassifier(class_weight='balanced', max_depth=5, min_samples_leaf=0.05),\n",
    "                                 max_features=0.2, max_samples=0.3,\n",
    "                                 n_estimators=10, random_state=748)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb_bag_best = BaggingClassifier(base_estimator=GaussianNB(),\n",
    "                                 max_features=0.5, max_samples=0.2,\n",
    "                                 n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_estimators = [('lr', lr_best), ('lr_bag', lr_bag_best),\n",
    "                   ('lsvc', lsvc_best), ('lsvc_bag', lsvc_bag_best),\n",
    "                   ('dtc', dtc_best), ('dtc_bag_best', dtc_bag_best),\n",
    "                   ('rfc', rfc_best), ('rfc_bag', rfc_bag_best),\n",
    "                   ('gnb', gnb_bag_best)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 46.58s \n"
     ]
    }
   ],
   "source": [
    "vc_hard = VotingClassifier(estimators=best_estimators, voting='hard', n_jobs=4)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_hard.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.560 (+/- 0.005)\n",
      "Mean recall score = 0.741 (+/- 0.023)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(vc_hard, X_train, y_train, cv=5, scoring=f2_score), 'f2')\n",
    "my_func.print_cvs(cross_val_score(vc_hard, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               55288               43026\n",
      "Actual Positive                6344               17116\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.555779\n",
      "Recall           0.729582\n",
      "Precision (pos)  0.284593\n",
      "Precision (neg)  0.897066\n",
      "Specificity      0.562361\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, vc_hard.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               13887               10743\n",
      "Actual Positive                1622                4192\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.548820\n",
      "Recall           0.721018\n",
      "Precision (pos)  0.280683\n",
      "Precision (neg)  0.895416\n",
      "Specificity      0.563825\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, vc_hard.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore the possible benefits of exluding certain models from the ensemble (weight of 0) before moving on to intermediate weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [0, 1]\n",
    "weight_combos = list(product(weights, repeat=len(best_estimators)))[1:]\n",
    "\n",
    "len(weight_combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than fit every model each time, even when some are weighted as 0, we will pass different lists into the voting classifier so avoid as many unnecessary fits as possible. This is still likely to take a long time to run due to the number of combinations and models still being fit, so we will run this overnight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator_combo_list = [list(pd.Series(best_estimators)[pd.Series(weight_combos[i]) == 1]) for i in range(len(weight_combos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 511 candidates, totalling 1533 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed: 97.1min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 188.8min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed: 292.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 450min 60s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1533 out of 1533 | elapsed: 451.0min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "vc_hard_test = VotingClassifier(estimators=best_estimators, voting='hard')\n",
    "\n",
    "param_grid = {'estimators': estimator_combo_list}\n",
    "\n",
    "vc_hard_gs = GridSearchCV(estimator=vc_hard_test,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=3,\n",
    "                          scoring=scoring,\n",
    "                          refit=False,\n",
    "                          n_jobs=4,\n",
    "                          verbose=3)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_hard_gs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'estimators': [('lr_bag', Pipeline(memory=None,\n",
      "     steps=[('rfe', RFE(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),..._estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=998, verbose=0, warm_start=False))])), ('dtc', DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,\n",
      "            max_features=0.4, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=356,\n",
      "            splitter='best')), ('gnb', BaggingClassifier(base_estimator=GaussianNB(priors=None), bootstrap=True,\n",
      "         bootstrap_features=False, max_features=0.5, max_samples=0.2,\n",
      "         n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False))]}\n",
      "F2 = 0.574037890604848\n",
      "Recall = 0.8303494719600691\n",
      "Precision = 0.256947983787618\n",
      "Specificity = 0.4268567948593862\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'estimators': [('gnb', BaggingClassifier(base_estimator=GaussianNB(priors=None), bootstrap=True,\n",
      "         bootstrap_features=False, max_features=0.5, max_samples=0.2,\n",
      "         n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False))]}\n",
      "F2 = 0.5478245976335325\n",
      "Recall = 0.9175611737596001\n",
      "Precision = 0.211726959328173\n",
      "Specificity = 0.17378975761342347\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'estimators': [('lr', Pipeline(memory=None,\n",
      "     steps=[('rfe', RFE(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),...ty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])), ('dtc_bag_best', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=0.7,\n",
      "         max_samples=0.2, n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=321, verbose=0, warm_start=False))]}\n",
      "F2 = 0.5208713581102988\n",
      "Recall = 0.6349955781572983\n",
      "Precision = 0.3031345609955867\n",
      "Specificity = 0.6516772613890304\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'estimators': [('lr_bag', Pipeline(memory=None,\n",
      "     steps=[('rfe', RFE(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),..._estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=998, verbose=0, warm_start=False))])), ('rfc_bag', BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=5, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=0.05,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=0.2,\n",
      "         max_samples=0.3, n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=748, verbose=0, warm_start=False))]}\n",
      "F2 = 0.5143808696011031\n",
      "Recall = 0.6261293214880427\n",
      "Precision = 0.3007524952175314\n",
      "Specificity = 0.6521552867218202\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "gs_summary = my_func.gs_score_summary(vc_hard_gs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F2</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.566349</td>\n",
       "      <td>0.271771</td>\n",
       "      <td>0.776897</td>\n",
       "      <td>0.503204</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.566066</td>\n",
       "      <td>0.272458</td>\n",
       "      <td>0.775149</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>[(lr_bag, Pipeline(memory=None,\\n     steps=[(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.566021</td>\n",
       "      <td>0.271690</td>\n",
       "      <td>0.776939</td>\n",
       "      <td>0.502502</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.565298</td>\n",
       "      <td>0.272886</td>\n",
       "      <td>0.772677</td>\n",
       "      <td>0.508107</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.564981</td>\n",
       "      <td>0.272705</td>\n",
       "      <td>0.771824</td>\n",
       "      <td>0.508808</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.564409</td>\n",
       "      <td>0.272557</td>\n",
       "      <td>0.771057</td>\n",
       "      <td>0.508595</td>\n",
       "      <td>[(lsvc, Pipeline(memory=None,\\n     steps=[('r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.564359</td>\n",
       "      <td>0.272865</td>\n",
       "      <td>0.770034</td>\n",
       "      <td>0.510344</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.564268</td>\n",
       "      <td>0.273024</td>\n",
       "      <td>0.769480</td>\n",
       "      <td>0.511087</td>\n",
       "      <td>[(lr_bag, Pipeline(memory=None,\\n     steps=[(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.564256</td>\n",
       "      <td>0.274246</td>\n",
       "      <td>0.767050</td>\n",
       "      <td>0.515623</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.564243</td>\n",
       "      <td>0.274668</td>\n",
       "      <td>0.766198</td>\n",
       "      <td>0.517200</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           F2  precision    recall  specificity  \\\n",
       "378  0.566349   0.271771  0.776897     0.503204   \n",
       "210  0.566066   0.272458  0.775149     0.505747   \n",
       "326  0.566021   0.271690  0.776939     0.502502   \n",
       "470  0.565298   0.272886  0.772677     0.508107   \n",
       "432  0.564981   0.272705  0.771824     0.508808   \n",
       "114  0.564409   0.272557  0.771057     0.508595   \n",
       "424  0.564359   0.272865  0.770034     0.510344   \n",
       "232  0.564268   0.273024  0.769480     0.511087   \n",
       "500  0.564256   0.274246  0.767050     0.515623   \n",
       "504  0.564243   0.274668  0.766198     0.517200   \n",
       "\n",
       "                                            estimators  \n",
       "378  [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  \n",
       "210  [(lr_bag, Pipeline(memory=None,\\n     steps=[(...  \n",
       "326  [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  \n",
       "470  [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  \n",
       "432  [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  \n",
       "114  [(lsvc, Pipeline(memory=None,\\n     steps=[('r...  \n",
       "424  [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  \n",
       "232  [(lr_bag, Pipeline(memory=None,\\n     steps=[(...  \n",
       "500  [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  \n",
       "504  [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_summary[gs_summary['specificity'] >= 0.5].sort_values('F2', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lr', Pipeline(memory=None,\n",
       "       steps=[('rfe', RFE(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),...ty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])),\n",
       " ('lsvc', Pipeline(memory=None,\n",
       "       steps=[('rfe', RFE(estimator=LinearSVC(C=1.0, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "       verbose=0),\n",
       "    n_features_to_select=31, step=1, verbose=0)), ...ax_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "       verbose=0))])),\n",
       " ('lsvc_bag',\n",
       "  BaggingClassifier(base_estimator=LinearSVC(C=1e-07, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "       verbose=0),\n",
       "           bootstrap=False, bootstrap_features=False, max_features=0.8,\n",
       "           max_samples=0.2, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "           random_state=521, verbose=0, warm_start=False)),\n",
       " ('dtc',\n",
       "  DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,\n",
       "              max_features=0.4, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=356,\n",
       "              splitter='best')),\n",
       " ('dtc_bag_best',\n",
       "  BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best'),\n",
       "           bootstrap=False, bootstrap_features=False, max_features=0.7,\n",
       "           max_samples=0.2, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "           random_state=321, verbose=0, warm_start=False)),\n",
       " ('rfc_bag',\n",
       "  BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "              criterion='gini', max_depth=5, max_features='auto',\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=0.05,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False),\n",
       "           bootstrap=True, bootstrap_features=False, max_features=0.2,\n",
       "           max_samples=0.3, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "           random_state=748, verbose=0, warm_start=False)),\n",
       " ('gnb',\n",
       "  BaggingClassifier(base_estimator=GaussianNB(priors=None), bootstrap=True,\n",
       "           bootstrap_features=False, max_features=0.5, max_samples=0.2,\n",
       "           n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_summary.loc[378]['estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_estimators = [('lr', lr_best),\n",
    "                   ('lsvc', lsvc_best), ('lsvc_bag', lsvc_bag_best),\n",
    "                   ('dtc', dtc_best), ('dtc_bag_best', dtc_bag_best),\n",
    "                   ('rfc_bag', rfc_bag_best),\n",
    "                   ('gnb', gnb_bag_best)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 37.00s \n"
     ]
    }
   ],
   "source": [
    "vc_hard = VotingClassifier(estimators=best_estimators, voting='hard', n_jobs=4)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_hard.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2 score = 0.565 (+/- 0.003)\n",
      "Mean recall score = 0.776 (+/- 0.004)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(vc_hard, X_train, y_train, cv=5, scoring=f2_score), 'f2')\n",
    "my_func.print_cvs(cross_val_score(vc_hard, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               51609               46705\n",
      "Actual Positive                5616               17844\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.563297\n",
      "Recall           0.760614\n",
      "Precision (pos)  0.276441\n",
      "Precision (neg)  0.901861\n",
      "Specificity      0.524940\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, vc_hard.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               12977               11653\n",
      "Actual Positive                1409                4405\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.560233\n",
      "Recall           0.757654\n",
      "Precision (pos)  0.274318\n",
      "Precision (neg)  0.902058\n",
      "Specificity      0.526878\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, vc_hard.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will see if further tweaking the weights of our remaining base estimators can yield any additional improvements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [0.5, 1]\n",
    "weight_combos = list(product(weights, repeat=len(best_estimators)))[1:]\n",
    "\n",
    "len(weight_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 127 candidates, totalling 381 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 70.3min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed: 204.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 214min 58s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 381 out of 381 | elapsed: 215.0min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "param_grid = {'weights': weight_combos}\n",
    "\n",
    "vc_hard_gs_2 = GridSearchCV(estimator=vc_hard,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=3,\n",
    "                          scoring=scoring,\n",
    "                          refit=False,\n",
    "                          n_jobs=4,\n",
    "                          verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_hard_gs_2.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'weights': (0.5, 1, 0.5, 1, 1, 0.5, 1)}\n",
      "F2 = 0.5708101459008253\n",
      "Recall = 0.802642812350765\n",
      "Precision = 0.26485968825442713\n",
      "Specificity = 0.46831582728346566\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'weights': (0.5, 0.5, 0.5, 1, 0.5, 0.5, 1)}\n",
      "F2 = 0.5706436085295054\n",
      "Recall = 0.8040067956165665\n",
      "Precision = 0.26407406129180405\n",
      "Specificity = 0.4653050549230843\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'weights': (0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5)}\n",
      "F2 = 0.5536680596799513\n",
      "Recall = 0.7276212271468294\n",
      "Precision = 0.28325133314029527\n",
      "Specificity = 0.5605304988098141\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'weights': (0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5)}\n",
      "F2 = 0.5536680596799513\n",
      "Recall = 0.7276212271468294\n",
      "Precision = 0.28325133314029527\n",
      "Specificity = 0.5605304988098141\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "gs_summary_2 = my_func.gs_score_summary(vc_hard_gs_2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F2</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.567430</td>\n",
       "      <td>0.271567</td>\n",
       "      <td>0.779838</td>\n",
       "      <td>0.500865</td>\n",
       "      <td>(1, 0.5, 0.5, 0.5, 1, 0.5, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.567308</td>\n",
       "      <td>0.271553</td>\n",
       "      <td>0.779838</td>\n",
       "      <td>0.500509</td>\n",
       "      <td>(1, 0.5, 0.5, 0.5, 0.5, 0.5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.567092</td>\n",
       "      <td>0.271541</td>\n",
       "      <td>0.779113</td>\n",
       "      <td>0.501251</td>\n",
       "      <td>(0.5, 1, 0.5, 1, 0.5, 0.5, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.566959</td>\n",
       "      <td>0.271243</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.500305</td>\n",
       "      <td>(1, 1, 0.5, 1, 1, 0.5, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.566866</td>\n",
       "      <td>0.271262</td>\n",
       "      <td>0.779156</td>\n",
       "      <td>0.500519</td>\n",
       "      <td>(1, 0.5, 1, 1, 1, 0.5, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           F2  precision    recall  specificity  \\\n",
       "67   0.567430   0.271567  0.779838     0.500865   \n",
       "64   0.567308   0.271553  0.779838     0.500509   \n",
       "39   0.567092   0.271541  0.779113     0.501251   \n",
       "107  0.566959   0.271243  0.779412     0.500305   \n",
       "92   0.566866   0.271262  0.779156     0.500519   \n",
       "\n",
       "                             weights  \n",
       "67   (1, 0.5, 0.5, 0.5, 1, 0.5, 0.5)  \n",
       "64   (1, 0.5, 0.5, 0.5, 0.5, 0.5, 1)  \n",
       "39   (0.5, 1, 0.5, 1, 0.5, 0.5, 0.5)  \n",
       "107      (1, 1, 0.5, 1, 1, 0.5, 0.5)  \n",
       "92         (1, 0.5, 1, 1, 1, 0.5, 1)  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_summary_2[gs_summary_2['specificity'] >= 0.5].sort_values('F2', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 37.44s \n"
     ]
    }
   ],
   "source": [
    "vc_hard = VotingClassifier(estimators=best_estimators, voting='hard', weights=(1, 0.5, 0.5, 0.5, 1, 0.5, 0.5), n_jobs=4)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_hard.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall score = 0.776 (+/- 0.007)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(vc_hard, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               50530               47784\n",
      "Actual Positive                5427               18033\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.564742\n",
      "Recall           0.768670\n",
      "Precision (pos)  0.273987\n",
      "Precision (neg)  0.903015\n",
      "Specificity      0.513965\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, vc_hard.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               12705               11925\n",
      "Actual Positive                1363                4451\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.561541\n",
      "Recall           0.765566\n",
      "Precision (pos)  0.271800\n",
      "Precision (neg)  0.903113\n",
      "Specificity      0.515834\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, vc_hard.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This achieves slightly better performance than our previous ensemble with uniform weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to proceed with a soft voting classifier, we need the SVC to return class probabilities. This is only possible with the regular SVC model, but this is less efficient than LinearSVC. We will see how runtimes look for fitting the linear SVC model on its own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 19min 35s \n"
     ]
    }
   ],
   "source": [
    "svc_best = Pipeline([('rfe', RFE(estimator=LinearSVC(class_weight='balanced', dual=False), n_features_to_select=31)),\n",
    "                      ('estimator', SVC(kernel='linear', class_weight='balanced', C=1e-7, cache_size=2000))])\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "svc_best.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the soft classifier with the Linear SVC included will inevitably take a while to process due to the time it takes the SVC model to fit and produce, especially since the above fit does not even take into consideration the time needed for returning the probabilities. We will start with a soft voting classifier which excludes the linear SVC model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 41.54s \n"
     ]
    }
   ],
   "source": [
    "best_estimators = [('lr', lr_best), ('lr_bag', lr_bag_best),\n",
    "                   ('dtc', dtc_best), ('dtc_bag_best', dtc_bag_best),\n",
    "                   ('rfc', rfc_best), ('rfc_bag', rfc_bag_best),\n",
    "                   ('gnb', gnb_bag_best)]\n",
    "\n",
    "vc_soft = VotingClassifier(estimators=best_estimators, voting='soft', n_jobs=4)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_soft.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall score = 0.755 (+/- 0.020)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(vc_soft, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               58496               39818\n",
      "Actual Positive                7312               16148\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.538964\n",
      "Recall           0.688321\n",
      "Precision (pos)  0.288532\n",
      "Precision (neg)  0.888889\n",
      "Specificity      0.594992\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, vc_soft.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               14675                9955\n",
      "Actual Positive                1843                3971\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.533995\n",
      "Recall           0.683007\n",
      "Precision (pos)  0.285150\n",
      "Precision (neg)  0.888425\n",
      "Specificity      0.595818\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, vc_soft.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, the soft voting classifier seems to perform significantly worse than our hard voting classifier. We will see if we can improve this by adjusting weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [0, 1]\n",
    "weight_combos = list(product(weights, repeat=len(best_estimators)))[1:]\n",
    "\n",
    "len(weight_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator_combo_list = [list(pd.Series(best_estimators)[pd.Series(weight_combos[i]) == 1]) for i in range(len(weight_combos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 127 candidates, totalling 381 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 52.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 88min 36s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 381 out of 381 | elapsed: 88.6min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "vc_soft_test = VotingClassifier(estimators=best_estimators, voting='soft')\n",
    "\n",
    "param_grid = {'estimators': estimator_combo_list}\n",
    "\n",
    "vc_soft_gs = GridSearchCV(estimator=vc_soft_test,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=3,\n",
    "                          scoring=scoring,\n",
    "                          refit=False,\n",
    "                          n_jobs=4,\n",
    "                          verbose=3)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_soft_gs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'estimators': [('lr', Pipeline(memory=None,\n",
      "     steps=[('rfe', RFE(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),...ty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])), ('lr_bag', Pipeline(memory=None,\n",
      "     steps=[('rfe', RFE(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),..._estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=998, verbose=0, warm_start=False))])), ('rfc', RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features=0.5,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=0.095,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=808,\n",
      "            verbose=0, warm_start=False)), ('gnb', BaggingClassifier(base_estimator=GaussianNB(priors=None), bootstrap=True,\n",
      "         bootstrap_features=False, max_features=0.5, max_samples=0.2,\n",
      "         n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False))]}\n",
      "F2 = 0.5701519054741526\n",
      "Recall = 0.8838024724178792\n",
      "Precision = 0.23603529573229148\n",
      "Specificity = 0.31587578500503677\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'estimators': [('lr_bag', Pipeline(memory=None,\n",
      "     steps=[('rfe', RFE(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),..._estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=998, verbose=0, warm_start=False))])), ('rfc_bag', BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=5, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=0.05,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=0.2,\n",
      "         max_samples=0.3, n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=748, verbose=0, warm_start=False)), ('gnb', BaggingClassifier(base_estimator=GaussianNB(priors=None), bootstrap=True,\n",
      "         bootstrap_features=False, max_features=0.5, max_samples=0.2,\n",
      "         n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False))]}\n",
      "F2 = 0.5460657814931679\n",
      "Recall = 0.9796675517352865\n",
      "Precision = 0.19712223931099918\n",
      "Specificity = 0.047745005225408296\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'estimators': [('dtc', DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,\n",
      "            max_features=0.4, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=356,\n",
      "            splitter='best')), ('dtc_bag_best', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=0.7,\n",
      "         max_samples=0.2, n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=321, verbose=0, warm_start=False))]}\n",
      "F2 = 0.5366917025075159\n",
      "Recall = 0.6919437949222695\n",
      "Precision = 0.28303156781574595\n",
      "Specificity = 0.5813923172287825\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'estimators': [('dtc', DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,\n",
      "            max_features=0.4, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=356,\n",
      "            splitter='best')), ('dtc_bag_best', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=0.7,\n",
      "         max_samples=0.2, n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=321, verbose=0, warm_start=False))]}\n",
      "F2 = 0.5366917025075159\n",
      "Recall = 0.6919437949222695\n",
      "Precision = 0.28303156781574595\n",
      "Specificity = 0.5813923172287825\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "vc_soft_gs_summary = my_func.gs_score_summary(vc_soft_gs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F2</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.560162</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>0.766453</td>\n",
       "      <td>0.504882</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.559535</td>\n",
       "      <td>0.269915</td>\n",
       "      <td>0.764791</td>\n",
       "      <td>0.506144</td>\n",
       "      <td>[(dtc, DecisionTreeClassifier(class_weight='ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.559266</td>\n",
       "      <td>0.270934</td>\n",
       "      <td>0.762020</td>\n",
       "      <td>0.510680</td>\n",
       "      <td>[(lr_bag, Pipeline(memory=None,\\n     steps=[(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.558711</td>\n",
       "      <td>0.277600</td>\n",
       "      <td>0.748124</td>\n",
       "      <td>0.535427</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.558602</td>\n",
       "      <td>0.278218</td>\n",
       "      <td>0.746760</td>\n",
       "      <td>0.537706</td>\n",
       "      <td>[(lr, Pipeline(memory=None,\\n     steps=[('rfe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           F2  precision    recall  specificity  \\\n",
       "122  0.560162   0.269750  0.766453     0.504882   \n",
       "30   0.559535   0.269915  0.764791     0.506144   \n",
       "60   0.559266   0.270934  0.762020     0.510680   \n",
       "95   0.558711   0.277600  0.748124     0.535427   \n",
       "63   0.558602   0.278218  0.746760     0.537706   \n",
       "\n",
       "                                            estimators  \n",
       "122  [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  \n",
       "30   [(dtc, DecisionTreeClassifier(class_weight='ba...  \n",
       "60   [(lr_bag, Pipeline(memory=None,\\n     steps=[(...  \n",
       "95   [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  \n",
       "63   [(lr, Pipeline(memory=None,\\n     steps=[('rfe...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_soft_gs_summary[vc_soft_gs_summary['specificity'] >= 0.5].sort_values('F2', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lr', Pipeline(memory=None,\n",
       "       steps=[('rfe', RFE(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),...ty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])),\n",
       " ('lr_bag', Pipeline(memory=None,\n",
       "       steps=[('rfe', RFE(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),..._estimators=10, n_jobs=1, oob_score=False,\n",
       "           random_state=998, verbose=0, warm_start=False))])),\n",
       " ('dtc',\n",
       "  DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,\n",
       "              max_features=0.4, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=356,\n",
       "              splitter='best')),\n",
       " ('dtc_bag_best',\n",
       "  BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best'),\n",
       "           bootstrap=False, bootstrap_features=False, max_features=0.7,\n",
       "           max_samples=0.2, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "           random_state=321, verbose=0, warm_start=False)),\n",
       " ('rfc_bag',\n",
       "  BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "              criterion='gini', max_depth=5, max_features='auto',\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=0.05,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False),\n",
       "           bootstrap=True, bootstrap_features=False, max_features=0.2,\n",
       "           max_samples=0.3, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "           random_state=748, verbose=0, warm_start=False)),\n",
       " ('gnb',\n",
       "  BaggingClassifier(base_estimator=GaussianNB(priors=None), bootstrap=True,\n",
       "           bootstrap_features=False, max_features=0.5, max_samples=0.2,\n",
       "           n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_soft_gs_summary.iloc[122]['estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_estimators = [('lr', lr_best), ('lr_bag', lr_bag_best),\n",
    "                   ('dtc', dtc_best), ('dtc_bag_best', dtc_bag_best),\n",
    "                   ('rfc_bag', rfc_bag_best),\n",
    "                   ('gnb', gnb_bag_best)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 38.74s \n"
     ]
    }
   ],
   "source": [
    "vc_soft = VotingClassifier(estimators=best_estimators, voting='soft', n_jobs=4)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_soft.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall score = 0.745 (+/- 0.062)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(vc_soft, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               54213               44101\n",
      "Actual Positive                6307               17153\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.552987\n",
      "Recall           0.731159\n",
      "Precision (pos)  0.280031\n",
      "Precision (neg)  0.895787\n",
      "Specificity      0.551427\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, vc_soft.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               13590               11040\n",
      "Actual Positive                1603                4211\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.546784\n",
      "Recall           0.724286\n",
      "Precision (pos)  0.276113\n",
      "Precision (neg)  0.894491\n",
      "Specificity      0.551766\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, vc_soft.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant improvement over the previous soft voting classifier, but it still lags behind that of our hard voting classifier. Perhaps improvements can be made in changing the weights of the remaining estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 63 candidates, totalling 189 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 66.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 81min 42s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 189 out of 189 | elapsed: 81.7min finished\n"
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision':'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "vc_soft = VotingClassifier(estimators=best_estimators, voting='soft')\n",
    "\n",
    "weights = [0.5, 1]\n",
    "weight_combos = list(product(weights, repeat=len(best_estimators)))[1:]\n",
    "\n",
    "param_grid = {'weights': weight_combos}\n",
    "\n",
    "vc_soft_gs = GridSearchCV(estimator=vc_soft,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=3,\n",
    "                          scoring=scoring,\n",
    "                          refit=False,\n",
    "                          n_jobs=4,\n",
    "                          verbose=2)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_soft_gs.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us evaluate the performance of our best combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Best F2:\n",
      "Params: {'weights': (0.5, 0.5, 0.5, 0.5, 1, 1)}\n",
      "F2 = 0.5705391428126331\n",
      "Recall = 0.8693523613425516\n",
      "Precision = 0.2412568505870144\n",
      "Specificity = 0.34390842762745616\n",
      "--------------------\n",
      "Best Recall:\n",
      "Params: {'weights': (0.5, 0.5, 0.5, 0.5, 0.5, 1)}\n",
      "F2 = 0.5682590403641337\n",
      "Recall = 0.893861478836083\n",
      "Precision = 0.23253861665127348\n",
      "Specificity = 0.2907519023929422\n",
      "--------------------\n",
      "Best Precision:\n",
      "Params: {'weights': (1, 0.5, 1, 1, 0.5, 0.5)}\n",
      "F2 = 0.5462261157784691\n",
      "Recall = 0.7187125645566141\n",
      "Precision = 0.2790179322966122\n",
      "Specificity = 0.5563907377889018\n",
      "--------------------\n",
      "Best Specificity:\n",
      "Params: {'weights': (1, 0.5, 1, 1, 0.5, 0.5)}\n",
      "F2 = 0.5462261157784691\n",
      "Recall = 0.7187125645566141\n",
      "Precision = 0.2790179322966122\n",
      "Specificity = 0.5563907377889018\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "vc_soft_gs_summary = my_func.gs_score_summary(vc_soft_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F2</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.560171</td>\n",
       "      <td>0.271404</td>\n",
       "      <td>0.763299</td>\n",
       "      <td>0.510924</td>\n",
       "      <td>(1, 0.5, 1, 0.5, 1, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.559832</td>\n",
       "      <td>0.270206</td>\n",
       "      <td>0.764791</td>\n",
       "      <td>0.507059</td>\n",
       "      <td>(1, 1, 1, 1, 0.5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.559209</td>\n",
       "      <td>0.271568</td>\n",
       "      <td>0.760656</td>\n",
       "      <td>0.513152</td>\n",
       "      <td>(1, 0.5, 1, 0.5, 0.5, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.559095</td>\n",
       "      <td>0.270868</td>\n",
       "      <td>0.762106</td>\n",
       "      <td>0.509968</td>\n",
       "      <td>(0.5, 1, 1, 1, 0.5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.558757</td>\n",
       "      <td>0.269573</td>\n",
       "      <td>0.767008</td>\n",
       "      <td>0.500631</td>\n",
       "      <td>(1, 0.5, 1, 1, 0.5, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F2  precision    recall  specificity                     weights\n",
       "41  0.560171   0.271404  0.763299     0.510924    (1, 0.5, 1, 0.5, 1, 0.5)\n",
       "60  0.559832   0.270206  0.764791     0.507059        (1, 1, 1, 1, 0.5, 1)\n",
       "39  0.559209   0.271568  0.760656     0.513152  (1, 0.5, 1, 0.5, 0.5, 0.5)\n",
       "28  0.559095   0.270868  0.762106     0.509968      (0.5, 1, 1, 1, 0.5, 1)\n",
       "44  0.558757   0.269573  0.767008     0.500631      (1, 0.5, 1, 1, 0.5, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_soft_gs_summary[vc_soft_gs_summary['specificity'] >= 0.5].sort_values('F2', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.5, 1, 0.5, 1, 0.5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_soft_gs_summary.iloc[41]['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 38.27s \n"
     ]
    }
   ],
   "source": [
    "best_estimators = [('lr', lr_best), ('lr_bag', lr_bag_best),\n",
    "                   ('dtc', dtc_best), ('dtc_bag_best', dtc_bag_best),\n",
    "                   ('rfc_bag', rfc_bag_best),\n",
    "                   ('gnb', gnb_bag_best)]\n",
    "\n",
    "w = (1, 0.5, 1, 0.5, 1, 0.5)\n",
    "\n",
    "vc_soft = VotingClassifier(estimators=best_estimators, voting='soft', weights=w, n_jobs=4)\n",
    "\n",
    "my_func.run_time(reset=True)\n",
    "vc_soft.fit(X_train, y_train)\n",
    "my_func.run_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall score = 0.758 (+/- 0.006)\n"
     ]
    }
   ],
   "source": [
    "my_func.print_cvs(cross_val_score(vc_soft, X_train, y_train, cv=5, scoring='recall'), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               52499               45815\n",
      "Actual Positive                5967               17493\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.556577\n",
      "Recall           0.745652\n",
      "Precision (pos)  0.276316\n",
      "Precision (neg)  0.897941\n",
      "Specificity      0.533993\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_train, vc_soft.predict(X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               13166               11464\n",
      "Actual Positive                1512                4302\n",
      "--------------------\n",
      "Accuracy Scores:\n",
      "                    Score\n",
      "Rate                     \n",
      "F2               0.551228\n",
      "Recall           0.739938\n",
      "Precision (pos)  0.272866\n",
      "Precision (neg)  0.896989\n",
      "Specificity      0.534551\n"
     ]
    }
   ],
   "source": [
    "my_func.classifier_summary(y_val, vc_soft.predict(X_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soft voting classifier does not seem to able to outperform the results from the hard voting classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Randomized Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = Pipeline([('rfe', RFE(estimator=LogisticRegression(class_weight='balanced'))),\n",
    "               ('estimator', LogisticRegression(class_weight='balanced'))])\n",
    "\n",
    "lr_bag = Pipeline([('rfe', RFE(estimator=LogisticRegression(class_weight='balanced'))),\n",
    "                   ('estimator', BaggingClassifier(base_estimator=LogisticRegression(class_weight='balanced')))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc = Pipeline([('rfe', RFE(estimator=LinearSVC(class_weight='balanced', dual=False))),\n",
    "                 ('estimator', LinearSVC(class_weight='balanced', dual=False))])\n",
    "\n",
    "lsvc_bag = Pipeline([('rfe', RFE(estimator=LinearSVC(class_weight='balanced', dual=False))),\n",
    "                     ('estimator', BaggingClassifier(base_estimator=LinearSVC(class_weight='balanced', dual=False)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(class_weight='balanced')\n",
    "\n",
    "dtc_bag = BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "rfc_bag = BaggingClassifier(base_estimator=RandomForestClassifier(class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb_bag = BaggingClassifier(base_estimator=GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bagging_params = {'max_features': np.arange(0.1,0.51,0.1),\n",
    "                  'max_samples': np.arange(0.1,0.31,0.1),\n",
    "                  'bootstrap': [True,False],\n",
    "                  'bootstrap_features': [True,False],\n",
    "                  'n_estimators': np.arange(10,31,1)}\n",
    "\n",
    "tree_params =  [\n",
    "                {'max_depth': np.arange(1,11),'max_features': np.arange(0.1,0.91,0.1)},\n",
    "                {'max_depth': np.arange(1,11),'max_features': np.arange(0.1,0.91,0.1),'min_impurity_decrease': np.arange(0.01,0.21, 0.01)},\n",
    "                {'max_depth': np.arange(1,11),'max_features': np.arange(0.1,0.91,0.1),'min_samples_split': np.arange(0.01,0.21, 0.01)},\n",
    "                {'max_depth': np.arange(1,11),'max_features': np.arange(0.1,0.91,0.1),'min_samples_leaf': np.arange(0.01,0.21, 0.01)}\n",
    "               ]\n",
    "\n",
    "tree_bagging_params = [{**bagging_params, **{'base_estimator__'+key : item for key,item in t.items()}} for t in tree_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "models['lr'] = (lr, {'rfe__n_features_to_select': np.arange(10,41,1),\n",
    "                     'estimator__C': np.logspace(-9,0,10)})\n",
    "\n",
    "models['lr_bag'] = (lr_bag, {**{'rfe__n_features_to_select': np.arange(10,41,1),'estimator__base_estimator__C': np.logspace(-9,0,10)},\n",
    "                             **{'estimator__'+key: item for key,item in bagging_params.items()}})\n",
    "\n",
    "models['lsvc'] = (lsvc, {'rfe__n_features_to_select': np.arange(10,41,1),\n",
    "                         'estimator__C': np.logspace(-9,0,10)})\n",
    "\n",
    "models['lsvc_bag'] = (lsvc_bag, {**{'rfe__n_features_to_select': np.arange(10,41,1),'estimator__base_estimator__C': np.logspace(-9,0,10)},\n",
    "                                 **{'estimator__'+key : item for key,item in bagging_params.items()}})\n",
    "\n",
    "models['dtc'] = (dtc, tree_params)\n",
    "\n",
    "models['dtc_bag'] = (dtc_bag, tree_bagging_params)\n",
    "\n",
    "models['rfc'] = (rfc, tree_params)\n",
    "\n",
    "models['rfc_bag'] = (rfc_bag, tree_bagging_params)\n",
    "\n",
    "models['gnb_bag'] = (gnb_bag, bagging_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble_randomizer(estimator_dict, n_estimators, random_state=None):\n",
    "    if random_state is not None:\n",
    "        random.seed(random_state)\n",
    "    estimators = []\n",
    "    estimator_counts = Counter()\n",
    "    for i in range(n_estimators):\n",
    "        key = random.choice(list(estimator_dict.keys()))\n",
    "        estimator_counts[key] += 1\n",
    "        estimator = clone(estimator_dict[key][0])\n",
    "        if type(estimator_dict[key][1]) is list:\n",
    "            param_dict = random.choice(estimator_dict[key][1])\n",
    "        else:\n",
    "            param_dict = estimator_dict[key][1]\n",
    "            \n",
    "        for param_name, param_values in param_dict.items():\n",
    "            estimator.set_params(**{param_name: random.choice(list(param_values))})\n",
    "        estimators.append((key + '_' + str(estimator_counts[key]), estimator))\n",
    "    \n",
    "    return estimators\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vch_models = models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c7f4337163f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m                               verbose=3)\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mrand_vc_hard_gs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 638\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision': 'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "\n",
    "vch_seeds = np.random.choice(1000,10,replace=False)\n",
    "vch_estimators = [ensemble_randomizer(vch_models, 100, rs) for rs in vch_seeds]\n",
    "param_grid = {'estimators': vch_estimators}\n",
    "\n",
    "vc_hard_test = VotingClassifier(estimators=(),voting='hard')\n",
    "\n",
    "rand_vc_hard_gs = GridSearchCV(estimator=vc_hard_test,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=3)\n",
    "\n",
    "rand_vc_hard_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcs_models = models.copy()\n",
    "\n",
    "try:\n",
    "    del vcs_models['lsvc'], vcs_models['lsvc_bag'] \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring={'F2': f2_score,\n",
    "         'recall':'recall',\n",
    "         'precision': 'precision',\n",
    "         'specificity': make_scorer(my_func.binary_specificity)}\n",
    "n = 100\n",
    "vcs_seeds = np.random.choice(1000,i,replace=False)\n",
    "vcs_estimators = [ensemble_randomizer(vcs_models, n, rs) for rs in vcs_seeds]\n",
    "param_grid = {'estimators': vcs_estimators}\n",
    "\n",
    "vc_soft_test = VotingClassifier(estimators=(),voting='soft')\n",
    "\n",
    "rand_vc_soft_gs = GridSearchCV(estimator=vc_soft_test,\n",
    "                              param_grid = param_grid,\n",
    "                              scoring=scoring,\n",
    "                              cv=3,\n",
    "                              refit=False,\n",
    "                              n_jobs=4,\n",
    "                              verbose=3)\n",
    "\n",
    "rand_vc_soft_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
