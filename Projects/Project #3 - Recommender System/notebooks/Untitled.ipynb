{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contingency_matrix(order_details, verbose=0):\n",
    "\n",
    "    # define item_list to hold our product pairing\n",
    "    item_list = pd.DataFrame(columns=['a', 'b'])\n",
    "    \n",
    "    n_orders = order_details['order_id'].nunique()\n",
    "    combo_list = []\n",
    "    start = time.time()\n",
    "    \n",
    "    # loop through order history by order ID\n",
    "    for i, (order_id, order_products) in enumerate(order_details.groupby('order_id')):\n",
    "        \n",
    "        if verbose > 0 and i > 0 and i%(n_orders//1000) == 0:\n",
    "            print('Building list... processing orders ({:.1f}%)'.format(100*(i+1)/n_orders), end='\\r')\n",
    "\n",
    "        # Get unique list of products in order\n",
    "        product_ids = list(order_products['product_id'].unique())\n",
    "\n",
    "        # Add all product combinations to main list\n",
    "        combo_list += list(itertools.product(product_ids,product_ids))\n",
    "\n",
    "    # Convert list of product combos to dataframe\n",
    "    item_list = pd.DataFrame(product_list, columns=['a','b'])    \n",
    "    # Create crosstab matrix from dataframe\n",
    "    if verbose > 0:\n",
    "        print('Performing cross tabulation...', ' '*50, end='\\r')\n",
    "    matrix = pd.crosstab(item_list.a, item_list.b)\n",
    "    \n",
    "    # Sort column values by purchase quantity (in descending order)\n",
    "    sorted_names = matrix.sum().sort_values(ascending=False).index.tolist()\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print('Complete ({:.0fs})'.format(time.time()-start), ' '*50)\n",
    "    \n",
    "    # return a sorted contingency matrix\n",
    "    return matrix.loc[sorted_names, sorted_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contingency_matrix(order_details, verbose=0):\n",
    "\n",
    "    # define item_list to hold our product pairing\n",
    "    item_list = pd.DataFrame(columns=['a', 'b'])\n",
    "    \n",
    "    n_orders = order_details['order_id'].nunique()\n",
    "    combo_list = []\n",
    "    start = time.time()\n",
    "    \n",
    "    # loop through order history by order ID\n",
    "    for i, (order_id, order_products) in enumerate(order_details.groupby('order_id')):\n",
    "        \n",
    "        if verbose > 0 and i > 0 and i%(n_orders//1000) == 0:\n",
    "            print('Building list... processing orders ({:.1f}%)'.format(100*(i+1)/n_orders), end='\\r')\n",
    "\n",
    "        # Get unique list of products in order\n",
    "        product_ids = list(order_products['product_id'].unique())\n",
    "\n",
    "        # Add all product combinations to main list\n",
    "        combo_list += [frozenset(a,b) for a,b in itertools.product(product_ids,product_ids)]\n",
    "\n",
    "    # Convert list of product combos to dataframe\n",
    "    item_list = pd.DataFrame(product_list, columns=['a','b'])    \n",
    "    # Create crosstab matrix from dataframe\n",
    "    if verbose > 0:\n",
    "        print('Performing cross tabulation...', ' '*50, end='\\r')\n",
    "    matrix = pd.crosstab(item_list.a, item_list.b)\n",
    "    \n",
    "    # Sort column values by purchase quantity (in descending order)\n",
    "    sorted_names = matrix.sum().sort_values(ascending=False).index.tolist()\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print('Complete ({:.0fs})'.format(time.time()-start), ' '*50)\n",
    "    \n",
    "    # return a sorted contingency matrix\n",
    "    return matrix.loc[sorted_names, sorted_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns frequency counts for items and item pairs\n",
    "def freq(iterable):\n",
    "    if type(iterable) == pd.core.series.Series:\n",
    "        return iterable.value_counts().rename(\"freq\")\n",
    "    else: \n",
    "        return pd.Series(Counter(iterable)).rename(\"freq\")\n",
    "\n",
    "    \n",
    "# Returns number of unique orders\n",
    "def order_count(order_item):\n",
    "    return len(set(order_item.index))\n",
    "\n",
    "\n",
    "# Returns generator that yields item pairs, one at a time\n",
    "def get_item_pairs(order_item):\n",
    "    order_item = order_item.reset_index().as_matrix()\n",
    "    for order_id, order_object in groupby(order_item, lambda x: x[0]):\n",
    "        item_list = [item[1] for item in order_object]\n",
    "              \n",
    "        for item_pair in combinations(item_list, 2):\n",
    "            yield item_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import OnehotTransactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_oht_df(order_details, verbose=0):\n",
    "    order_details_flattened = []\n",
    "    order_ids = []\n",
    "    n_orders = order_details['order_id'].nunique()\n",
    "    # loop through each order & flatten order to a single line\n",
    "    for i, (group, data) in enumerate(order_details.groupby('order_id')):\n",
    "        \n",
    "        if verbose > 0 and i > 0 and i%(n_orders//1000) == 0:\n",
    "            print('{}/{} ({:.1f}%)'.format(i+1, n_orders, 100*(i+1)/n_orders), end='\\r')\n",
    "        \n",
    "        # find product names\n",
    "        products_on_order = list(data['product_id'].values)\n",
    "\n",
    "        # append order Id and product names to new array\n",
    "        order_ids.append(group)\n",
    "        order_details_flattened.append(products_on_order)\n",
    "\n",
    "    # create one hot transaction\n",
    "    oht = TransactionEncoder()\n",
    "\n",
    "    # convert our flattened order data structure\n",
    "    oht_arr = oht.fit(order_details_flattened).transform(order_details_flattened)\n",
    "\n",
    "    # convert results to a dataframe and return\n",
    "    return pd.DataFrame(oht_arr, columns=oht.columns_, index=order_ids, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_contingency_matrix(data, dtype=np.uint32, sort_matrix=False, verbose=0):\n",
    "    # Function start time\n",
    "    start = time.time()\n",
    "    \n",
    "    # --- Part A: Product Combo Counts ---\n",
    "    \n",
    "    # Part A start time\n",
    "    start_a = time.time()\n",
    "    \n",
    "    # Number of unique orders to process\n",
    "    n_orders= data['order_id'].nunique()\n",
    "    \n",
    "    # Initialize counter\n",
    "    combo_counter = Counter()\n",
    "    \n",
    "    for i, (order_id, order_products) in enumerate(data.groupby('order_id')):\n",
    "\n",
    "            if verbose > 0 and i%(n_orders//1000) == 0:\n",
    "                print('Getting product counts... ({:.1f}%)'.format(100*(i+1)/n_orders), end='\\r')\n",
    "\n",
    "            # Get unique list of products in current order\n",
    "            product_ids = list(order_products['product_id'].unique())\n",
    "\n",
    "            # Increment counter for all 2-product combinations\n",
    "            for a,b in itertools.combinations(product_ids,2):\n",
    "                combo_counter[frozenset({a,b})] += 1\n",
    "                \n",
    "            # Increment counter for independent products (i.e. combined with self)\n",
    "            for a in product_ids:\n",
    "                combo_counter[frozenset({a})] += 1\n",
    "    \n",
    "    if verbose > 0:\n",
    "        td = time.time()-start_a\n",
    "        td_min = td//60\n",
    "        td_sec = td%60\n",
    "        td_pretty = ('{:.0f}min '.format(td_min) if td_min > 0 else '') + ('{:.0f}s'.format(td_sec))\n",
    "        print('Product counts completed [{}]'.format(td_pretty), ' '*50)\n",
    "    \n",
    "    # --- Part B: Build Contingency Matrix ---\n",
    "    \n",
    "    # Part B start time\n",
    "    start_b = time.time()\n",
    "    \n",
    "    # Number of combinations to process\n",
    "    n_combos = len(combo_counter)\n",
    "    # List of unique product ids\n",
    "    unique_products = data['product_id'].unique()\n",
    "    # Number of unique products\n",
    "    n_products = unique_products.shape[0]\n",
    "    \n",
    "    # Create numpy array of zeros to populate with counts\n",
    "    count_arr = np.zeros((n_products, n_products), dtype=dtype)\n",
    "    \n",
    "    for i, (p_set, n) in enumerate(combo_counter.items()):\n",
    "        # Convert count to reduce memory consumption\n",
    "        n = dtype(n)\n",
    "        \n",
    "        if verbose > 0 and i%(n_combos//1000)==0:\n",
    "            print('Populating table... ({:.1f}%)'.format(100*(i+1)/n_combos), end='\\r')\n",
    "        \n",
    "        # Handle regular product combo counts\n",
    "        p_tup = tuple(p_set)\n",
    "        if len(p_tup)>1:            \n",
    "            i = np.where(unique_products == p_tup[0])\n",
    "            j = np.where(unique_products == p_tup[1])\n",
    "            count_arr[i,j] = n\n",
    "            count_arr[j,i] = n\n",
    "        \n",
    "        # Handle combo counts with self\n",
    "        else:\n",
    "            i = np.where(unique_products == p_tup[0])\n",
    "            count_arr[i,i] = n\n",
    "    \n",
    "    # Counter no longer needed\n",
    "    del combo_counter\n",
    "    \n",
    "    df = pd.DataFrame(data=count_arr, index=unique_products, columns=unique_products, dtype=dtype)\n",
    "    \n",
    "    # Numpy array no longer needed\n",
    "    del count_arr\n",
    "    \n",
    "    if verbose > 0:\n",
    "        td = time.time()-start_b\n",
    "        td_min = td//60\n",
    "        td_sec = td%60\n",
    "        td_pretty = ('{:.0f}min '.format(td_min) if td_min > 0 else '') + ('{:.0f}s'.format(td_sec))\n",
    "        print('Populating table completed [{}]'.format(td_pretty), ' '*50)\n",
    "    \n",
    "    # --- Part C: Sort Matrix (Optional) ---\n",
    "    if sort_matrix:\n",
    "        start_c = time.time()\n",
    "        if verbose > 0:\n",
    "            print('Sorting values...',end='\\r')\n",
    "        \n",
    "        # Get list of sorted ids by total counts\n",
    "        sorted_ids = pd.Series(np.diag(df), index=df.index).sort_values(ascending=False).index.tolist()\n",
    "        # Sort dataframe by sorted ids\n",
    "        df = df.loc[sorted_ids, sorted_ids]\n",
    "        \n",
    "        if verbose > 0:\n",
    "            td = time.time()-start_c\n",
    "            td_min = td//60\n",
    "            td_sec = td%60\n",
    "            td_pretty = ('{:.0f}min '.format(td_min) if td_min > 0 else '') + ('{:.0f}s'.format(td_sec))\n",
    "            print('Sorting values completed [{}]'.format(td_pretty))\n",
    "    \n",
    "    if verbose > 0:\n",
    "        td = time.time()-start\n",
    "        td_min = td//60\n",
    "        td_sec = td%60\n",
    "        td_pretty = ('{:.0f}min '.format(td_min) if td_min > 0 else '') + ('{:.0f}s'.format(td_sec))\n",
    "        print('Total Runtime: [{}]'.format(td_pretty))\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
