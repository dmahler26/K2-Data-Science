{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os import path\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import random\n",
    "import time\n",
    "\n",
    "from dask.distributed import Client, progress\n",
    "import dask.delayed as delayed\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import src.my_helper as my_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.my_helper' from '..\\\\src\\\\my_helper.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imp import reload\n",
    "reload(my_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = ['..','data','processed']\n",
    "\n",
    "# Train set\n",
    "fp = path.join(*fd, 'train.p')\n",
    "with open(file=fp, mode='rb') as file:\n",
    "    train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = ['..','data','processed']\n",
    "\n",
    "# Train set\n",
    "fp = path.join(*fd, 'val.p')\n",
    "with open(file=fp, mode='rb') as file:\n",
    "    val = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Popularity Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderSystem():\n",
    "    '''\n",
    "    Base class for recommender systems\n",
    "    '''\n",
    "    MODEL_NAME = 'Base'\n",
    "    \n",
    "    def __init__(self, n_rec=10, rank=False, verbose=False, decay=False, decay_method='linear', decay_constant=None):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_rec: int, optional (default: 10)\n",
    "            Number of recommendations to return. Value of -1 returns full list.\n",
    "        rank: bool, optional (default: True)\n",
    "            Whether to include rank in index of returned recommendations. Note that results will typically be\n",
    "            sorted regardless of the inclusion of this rank index.\n",
    "        verbose: bool, optional (default: False)\n",
    "            Whether to print status/progress during processing. Implementation may vary depending on model complexity. \n",
    "        '''\n",
    "        self.n_rec = n_rec\n",
    "        self.verbose = verbose\n",
    "        self.rank = rank\n",
    "        \n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(data=None):\n",
    "        '''\n",
    "        Dummy base class fit method.\n",
    "        '''\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def get_model_name(self):\n",
    "        '''\n",
    "        Get model name.\n",
    "        '''\n",
    "        return self.MODEL_NAME\n",
    "    \n",
    "    def get_params(self):\n",
    "        '''\n",
    "        Get model parameters.\n",
    "        Returns: dict\n",
    "        '''\n",
    "        d = {'n_rec': self.n_rec,\n",
    "             'rank': self.rank,\n",
    "             'verbose': self.verbose}\n",
    "        \n",
    "        return d\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        '''\n",
    "        Set model parameters.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_rec: int, optional\n",
    "            Provides option to overwrite existing n_rec parameter for the number of recommendations to return per user.\n",
    "            A value of -1 returns the full list. \n",
    "        rank: bool, optional\n",
    "            Provides option to overwrite existing rank parameter to include ranking index values of recommendations.\n",
    "            Note that recommendations will be returned sorted by rank regardless of the inclusion of this index.\n",
    "        verbose: bool, optional\n",
    "            Whether to print status/progress during processing. Implementation may vary depending on model complexity.            \n",
    "        ----------\n",
    "        '''\n",
    "        self.n_rec = kwargs.pop('n_rec', self.n_rec)\n",
    "        self.verbose = kwargs.pop('verbose', self.verbose)\n",
    "        self.rank = kwargs.pop('rank', self.rank)\n",
    "        \n",
    "        if len(kwargs) > 0:\n",
    "            warnings.warn('Parameters {} not found and have been ignored.'.format(list(kwargs.keys())))\n",
    "            \n",
    "    def recommend(self, df_rec=None):\n",
    "        '''\n",
    "        Base recommend method. Not implemented for use outside of child recommenders.\n",
    "        '''\n",
    "        # Check if called without provides recommendation results (i.e. from actual recommender)\n",
    "        if df_rec is None:\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        if self.rank:\n",
    "            ranking = []\n",
    "            for user, recs in df_rec.groupby(level=0):\n",
    "                # Rank recs per user from 1:n_rec and append to overarching list\n",
    "                ranking += [i + 1 for i, rec in enumerate(recs)]\n",
    "            if type(df_rec) is pd.Series:\n",
    "                df_rec = df_rec.to_frame()\n",
    "            # Set generated list to new rank column (aligns with data)\n",
    "            df_rec['rank'] = ranking\n",
    "            # Set user id and rank as index\n",
    "            df_rec = df_rec.reset_index().set_index(['user_id', 'rank'])\n",
    "        \n",
    "        return df_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalPopularityRecommender(RecommenderSystem):\n",
    "    '''\n",
    "    Global Popularity Recommender system: produces recommendations based off most popular (i.e. frequently ordered)\n",
    "    items across all users.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_rec: int (default: -1)\n",
    "        Number of product recommendations to return. Setting to -1 will return all products ranked.\n",
    "    ----------\n",
    "    '''\n",
    "    MODEL_NAME = 'Global Popularity'\n",
    "    \n",
    "    def fit(self, data):\n",
    "        '''\n",
    "        Fit recommender using prior order product data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pandas.DataFrame\n",
    "            Dataframe containing history of order products. Assumes format of one row per product ordered.\n",
    "            Must contain column of 'product_id' on which to sum frequencies.\n",
    "        ----------\n",
    "        '''\n",
    "        # Produce sorted list of products IDs according to purchase frequency\n",
    "        self.sorted_product_ids = data['product_id'].value_counts().sort_values(ascending=False).index.values\n",
    "        self.fitted = True\n",
    "    \n",
    "    def recommend(self, user_id=0, **kwargs):\n",
    "        '''\n",
    "        Recommend products for a given user. Note that given the nature of this global popularity recommender,\n",
    "        recommendations are the same for all users, but user_id can still be provided for consistency amongst\n",
    "        recommender system parameters.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        user_id: int or array-like, optional (default: 0)\n",
    "            User ID to produce recommendations for. Note that for this particular recommender system, recommendations\n",
    "            are the same for all users and this parameter is merely included for consistency amongst recommenders.\n",
    "        ----------\n",
    "        Returns: pandas.DataFrame, index = ['user_id', 'rank'], cols = ['product_id]\n",
    "        '''\n",
    "        # Check if fit was performed\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError('cannot recommend without fitting!')\n",
    "        # Overwrite params if provided\n",
    "        self.set_params(**kwargs)\n",
    "        # Check user_id\n",
    "        if isinstance(user_id, (int, np.integer)):\n",
    "            user_id = [user_id]\n",
    "        if type(user_id) not in (list, np.ndarray):\n",
    "            raise ValueError('user_id not of accepted type. Must be int or array-like.')\n",
    "        \n",
    "        if self.n_rec == -1:\n",
    "            # get all products\n",
    "            df_rec = pd.Series(data=np.tile(self.sorted_product_ids,len(user_id)), index=np.repeat(user_id,self.sorted_product_ids.shape[0]), name='product_id')\n",
    "        else:\n",
    "            # get top n products\n",
    "            df_rec = pd.Series(data=np.tile(self.sorted_product_ids[:self.n_rec],len(user_id)), index=np.repeat(user_id,self.n_rec), name='product_id')\n",
    "        \n",
    "        df_rec.index.name = 'user_id'\n",
    "        \n",
    "        return super(GlobalPopularityRecommender, self).recommend(df_rec=df_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpop_rec = GlobalPopularityRecommender(n_rec=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpop_rec.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_name(product_id, fp=path.join('..','data','raw','products.csv'), reload=False):\n",
    "    '''\n",
    "    Get the product name for a given product_id. Function caches product data for successive calls, but can be forced\n",
    "    to reload data via 'reload' parameter.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    product_id: int or array-like\n",
    "        Product ID to retrieve name for.\n",
    "    fp: string, (default: path.join('..','data','raw','products.csv'))\n",
    "        Filepath from which to retrieve product csv data.\n",
    "    reload: bool (default: False)\n",
    "        Reload the product csv data.\n",
    "    ----------\n",
    "    Returns: product name (string) if ID found, else np.nan\n",
    "    '''\n",
    "    # shorthand for \"self\"\n",
    "    f = get_product_name\n",
    "    try:\n",
    "        f.product_data\n",
    "        if reload:\n",
    "            raise          \n",
    "    except:\n",
    "        # Load product data\n",
    "        with open(fp, 'rb') as file:\n",
    "            f.product_data = pd.read_csv(file, encoding='utf8').set_index('product_id')\n",
    "    \n",
    "    product_name = f.product_data.loc[product_id,'product_name'].values\n",
    "\n",
    "    return product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "7    24852\n",
       "7    13176\n",
       "7    21903\n",
       "7    21137\n",
       "7    47766\n",
       "7    47209\n",
       "7    47626\n",
       "7    16797\n",
       "7    26209\n",
       "7    27845\n",
       "Name: product_id, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpop_rec.recommend(user_id=7, rank=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Banana', 'Bag of Organic Bananas', 'Organic Baby Spinach',\n",
       "       'Organic Strawberries', 'Organic Avocado', 'Organic Hass Avocado',\n",
       "       'Large Lemon', 'Strawberries', 'Limes', 'Organic Whole Milk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_product_name(gpop_rec.recommend(user_id=7, n_rec=10).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Product List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = path.join('..','data','processed','products.p')\n",
    "with open(fp, 'rb') as file:\n",
    "    products = pickle.load(file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>All-Seasons Salt</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robust Golden Unsweetened Oolong Tea</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Smart Ones Classic Favorites Mini Rigatoni Wit...</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Green Chile Anytime Sauce</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                       product_name  aisle_id  \\\n",
       "0           1                         Chocolate Sandwich Cookies        61   \n",
       "1           2                                   All-Seasons Salt       104   \n",
       "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
       "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
       "4           5                          Green Chile Anytime Sauce         5   \n",
       "\n",
       "   department_id  \n",
       "0             19  \n",
       "1             13  \n",
       "2              7  \n",
       "3              1  \n",
       "4             13  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision@K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision @ K is probably the most basic performance evaluation method, but is a good place to start before building out other methods. We simply look at the set of products in each order, and calculate the proportion of products correctly recommended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_pk(order_products, rec_products, k=10):\n",
    "    '''\n",
    "    Calculate precision@k for a set of ordered products vs. recommended products.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    order_products: array-like\n",
    "        List of product IDs for a given order\n",
    "    rec_products: array-like\n",
    "        Sorted list of recommended product IDs (highest to lowest)\n",
    "    k: int, array-like (default = 10)\n",
    "        K threshold at which to evaluate precision\n",
    "    ----------\n",
    "    Returns: precision score (float)\n",
    "    '''\n",
    "    if isinstance(k, (int,np.integer)):\n",
    "        k = [k]\n",
    "    precisions = {}\n",
    "    for k_ in k:\n",
    "        # Get top K recommendations\n",
    "        top_n_recs = rec_products[:k_]\n",
    "\n",
    "        # Number of recommendations in order\n",
    "        n_hit = len(set(top_n_recs).intersection(order_products))\n",
    "\n",
    "        # Discount precision denominator for imbalances between # of recommendations and # of ordered products\n",
    "        m = min(len(order_products), len(top_n_recs))\n",
    "        # Proportion of correct recommendations\n",
    "        precisions['p@{:02d}'.format(k_)] = (n_hit / m)\n",
    "\n",
    "    return precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the calculation of precision is discounted for potential imbalances between the number of products in an order and the number of recommendations. For example, if 5 products are in an order and we have 10 recommended products which capture all 5 products in the order (extreme example), we do not want to punish scoring by saying only 5/10 were correct. Similarly, if we have an order of 10 products but only 5 recommendations, we again would not want to punish our scoring for only being able to recommend 5/10 products correctly. In both these scenarios, we would want to record 100% precision, since our recommendations have performend to the best of their ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set up a local cluster via Dask to process our validation set (20k orders):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:64120\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787' target='_blank'>http://127.0.0.1:8787</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>34.31 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:64120' processes=8 cores=8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert validation set to dask dataframe\n",
    "dd_val = dd.from_pandas(val.set_index('user_id'), npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = dd_val.index.unique()\n",
    "user_recs = delayed(gpop_rec.recommend)(user_id=unique_users.values, n_rec=10)\n",
    "user_recs = user_recs.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_eval = dd_val.groupby(['user_id', 'order_id'])['product_id'].apply(lambda x: order_pk(x, user_recs.loc[x.name[0]], [5,10]), meta=('precision@k', float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut = c.compute(dd_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6a90a5f2f142f590527837751aae38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0)))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress(fut, multi=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 seconds to process our 20k orders should be acceptable for repeated evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pk_results = fut.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id  order_id      \n",
       "7        2452257   p@05    0.2\n",
       "                   p@10    0.1\n",
       "13       1789302   p@05    0.0\n",
       "                   p@10    0.0\n",
       "14       3394109   p@05    0.0\n",
       "Name: precision@k, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p@05</th>\n",
       "      <th>p@10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>2452257</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>1789302</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>3394109</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <th>864720</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <th>29902</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  p@05  p@10\n",
       "user_id order_id            \n",
       "7       2452257    0.2   0.1\n",
       "13      1789302    0.0   0.0\n",
       "14      3394109    0.0   0.0\n",
       "65      864720     0.2   0.1\n",
       "70      29902      0.0   0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_results.unstack().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p@05    0.093233\n",
       "p@10    0.086623\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_results.unstack().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our precision at 5 and 10 both hover around 0.08-0.09. This is far from what we would hope to achieve in our actual models, and we should probably even consider expanding upon this baseline for a higher standard of comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MAP (Mean Average Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another evaluation metric is Mean Average Precision, which is akin to our Precision@K approach but also gives weight to the rank/position of the accurate recommendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_map(order_products, rec_products, n_range=10):\n",
    "    '''\n",
    "    Calculate the MAP score for a given set of orderered products and recommended products.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    order_products: array-like (int)\n",
    "        List of product IDs in a given order\n",
    "    rec_products: array-like (int)\n",
    "        List of recommended product IDs\n",
    "    n_range: int, array-like\n",
    "        Value or list of values at which to evaluate MAP. Scoring is calculated relative to the first n recommendations.\n",
    "    ---------\n",
    "    Returns: dict(string: float)\n",
    "    '''\n",
    "    if isinstance(n_range, (int, np.integer)):\n",
    "        n_range = [n_range]\n",
    "    order_product_set = set(order_products)\n",
    "    order_eval = {}\n",
    "    for n in n_range:\n",
    "        top_n_recs = rec_products[:n]\n",
    "        # Minimum of number of products in order or rec; avoids unfair scoring for length mismatches\n",
    "        m = min(len(order_product_set), n)\n",
    "        n_hit = 0\n",
    "        cum_prec = 0\n",
    "        for i, rec in enumerate(top_n_recs):\n",
    "            # Check if recommendation is contained in order\n",
    "            hit = int(rec in order_product_set)\n",
    "            # Increment hit count\n",
    "            n_hit += hit\n",
    "            # Cumulative precision of hits, dicounted for rank\n",
    "            cum_prec += hit*n_hit/(i+1)\n",
    "\n",
    "        # Mean precision according to number of products/recs\n",
    "        ap = cum_prec/m\n",
    "        order_eval['map@{:02d}'.format(n)] = ap\n",
    "    \n",
    "    return order_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert validation set to dask dataframe\n",
    "dd_val = dd.from_pandas(val.set_index('user_id'), npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = dd_val.index.unique()\n",
    "user_recs = delayed(pop_rec.recommend)(user_id=unique_users.values, n_rec=10)\n",
    "user_recs = user_recs.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_eval = dd_val.groupby(['user_id', 'order_id'])['product_id'].apply(lambda x: order_map(x, user_recs.loc[x.name[0]], [5,10,20]), meta=('map@k', float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut = c.compute(dd_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25e7fd8ea834efc96b729bdbd5fd3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0)))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress(fut, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_map_results = fut.result().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>map@05</th>\n",
       "      <th>map@10</th>\n",
       "      <th>map@20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>2452257</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>1789302</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>3394109</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <th>864720</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <th>29902</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  map@05  map@10    map@20\n",
       "user_id order_id                          \n",
       "7       2452257     0.05   0.025  0.020833\n",
       "13      1789302     0.00   0.000  0.000000\n",
       "14      3394109     0.00   0.000  0.000000\n",
       "65      864720      0.05   0.025  0.014706\n",
       "70      29902       0.00   0.000  0.000000"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_map_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "map@05    0.057445\n",
       "map@10    0.041477\n",
       "map@20    0.032851\n",
       "dtype: float64"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_map_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-N Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert validation set to dask dataframe\n",
    "dd_users = dd.from_array(val['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_val = dd.from_pandas(val.set_index('user_id'), npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 0: get full data\n",
    "train_full = pd.concat([train,val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: get product list\n",
    "full_product_list = products['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2: get user ordered products\n",
    "dd_full = dd.from_pandas(train_full, npartitions=8)\n",
    "dd_ord_prod = dd_full.groupby('user_id')['product_id'].apply(lambda x: x.unique(), meta=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_ord_prod = dd.from_pandas(train_full[['user_id','product_id']].drop_duplicates().set_index('user_id'), npartitions=8)\n",
    "ord_prod = dd_ord_prod.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3: get non ordered products\n",
    "def get_non_ordered_products(user_id):\n",
    "    ordered_products = ord_prod.loc[user_id]\n",
    "    non_ordered_product_set = set(full_product_list).difference(ordered_products)\n",
    "    return non_ordered_product_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_tna(user_id, order_products, rec_products, sample_size=100, n_range=10):\n",
    "    '''\n",
    "    Calculate Top-N Accuracy for a given user and set of order products and recommended products.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    user_id: int\n",
    "        User ID for which order is being evaluated. Required to pull list of non-ordered products for said user.\n",
    "    order_products: array-like (int)\n",
    "        List of products in a given order\n",
    "    rec_products: array-like (int)\n",
    "        List of recommended products (must be sorted by rank)\n",
    "    sample_size: int (default: 100)\n",
    "        Number of random non-purchased products to combine with each order product \n",
    "        when evaluating recommendation relevancy/effectiveness.\n",
    "    n_range: int, array-like (default: 10)\n",
    "        N value(s) at which to evaluate Top-N Accuracy.\n",
    "    ----------\n",
    "    Returns: dict(string: float)\n",
    "    '''\n",
    "    if isinstance(n_range, (int, np.integer)):\n",
    "        n_range = [n_range]\n",
    "        \n",
    "    non_ordered_products_set = get_non_ordered_products(user_id)\n",
    "    \n",
    "    order_eval = {}\n",
    "    hits_at_n = Counter()\n",
    "    for product_id in set(order_products):\n",
    "        # get 100 non purchased products\n",
    "        non_ordered_sample = set(random.sample(non_ordered_products_set, k=100))\n",
    "        # combine with product of interest\n",
    "        tna_sample = non_ordered_sample.union([product_id])\n",
    "        # rank products according to recs\n",
    "        ranked_products = rec_products[rec_products.isin(tna_sample)]\n",
    "        # top_n eval\n",
    "        for n in n_range:\n",
    "            if ranked_product_id in ranked_products.values[:n]:\n",
    "                hits_at_n[n] += 1\n",
    "    \n",
    "    n_products = len(order_products)\n",
    "    for n in n_range:\n",
    "        order_eval['tna@{:02d}'.format(n)] = hits_at_n[n]/n_products\n",
    "    \n",
    "    return order_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tna@10': 0.8333333333333334}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_tna(user_id=7, order_products=val.set_index(['user_id', 'order_id']).sort_index().loc[7, 2452257]['product_id'].values, rec_products=pop_rec.recommend(7, n_rec=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert validation set to dask dataframe\n",
    "dd_val = dd.from_pandas(val.set_index('user_id'), npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_eval = dd_val.groupby(['user_id', 'order_id'])['product_id'].apply(lambda x: order_tna(user_id=x.name, order_products=x, rec_products=gpop_rec.recommend(user_id=x.name, n_rec=-1), n_range=[5,10]), meta=('tna@k', float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut = c.compute(dd_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cdef35bda440c5baa168aa05129b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0)))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress(fut, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "tna_results = fut.result().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tna@05    0.686929\n",
       "tna@10    0.795457\n",
       "dtype: float64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tna_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scorings are clearly at a significantly higher magnitude than our previous Precision@K and MAP methods. This indicates that whilst our basic global recommender is rarely able to capture a signficant portion of ordered products in a given order, it does typically rank said products in the top 5/10 over samplings of products of (assumed) non-interest.\n",
    "\n",
    "However, these high scores do raise some concerns as to the effectiveness of this measure. It is possible that given the large set of products (close to 50k), there is an overwhelming proportion of completely irrelevant products for most customers. Consequently, when a sampling of 100 of these random products is combined with a given products of interest, things like popularity recommenders will fair disproportionally well due to a general bias toward the core set of ordered products. Our scores above consequently become something along the lines of 'our recommender ranks ordered products better than useless products 60-70% of the time', which is hardly a convincing measure.\n",
    "\n",
    "This issue may be alleviated by selecting a larger product sample (i.e. 1000 versus 100 non-purchased products), but this likely cause an additional to hit to performance. With processing times of our validation set of 20000 orders already taking close to 12 minutes, this evaluation method simply is not feasible for repeated use. Consequently, we should likely continue with MAP as a compromise between performance and robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator():\n",
    "    N_CORES = 8\n",
    "    \n",
    "    def __init__(self, eval_data, method='precision@k', n_range=[5,10]):\n",
    "        '''\n",
    "        Model evaluator class to perform scoring on recommender systems.\n",
    "        Utilizes dask distributed processing with the assumption a default client has already been configured.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        method: string (default: 'precision@k')\n",
    "            Scoring method to perform. Options are 'precision@k' (default), or 'map'\n",
    "        eval_data: pandas.DataFrame\n",
    "            Data on which to perform evaluation. Assumes columns of ['user_id', 'order_id', 'product_id],\n",
    "            with a row instance for each product ordered in a given order & user.\n",
    "        n_range: int, array-like (default: [5,10])\n",
    "            N value(s) at which to perform evaluation (i.e precision@10)\n",
    "        ----------\n",
    "        '''\n",
    "        # Set n_range\n",
    "        if isinstance(n_range, (int, np.integer)):\n",
    "            n_range = [n_range]\n",
    "        self.n_range = n_range\n",
    "        # Set list of unique products\n",
    "        self.product_list = None\n",
    "        # Set method\n",
    "        self.method = method\n",
    "        # Set eval data\n",
    "        self.eval_data = None\n",
    "        self.update_data(eval_data=eval_data)\n",
    "    \n",
    "    def update_data(self, eval_data):\n",
    "        '''\n",
    "        Update the data on which to perform evaluation\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        eval_data: pandas.DataFrame\n",
    "            Order-product data consisting columns for 'user_id' (int), 'order_id' (int), and 'product_id' (int).\n",
    "        ----------\n",
    "        '''\n",
    "        # Store eval data with User ID as index\n",
    "        self.eval_data = eval_data[['user_id', 'order_id', 'product_id']].copy().set_index('user_id').sort_index()\n",
    "        # List of unique users in evaluation dataset\n",
    "        self.unique_users = np.array(self.eval_data.index.unique())\n",
    "        # Number of unique users in evaluation dataset\n",
    "        self.nunique_users = self.unique_users.shape[0]\n",
    "    \n",
    "    def evaluate_model(self, model, method=None, eval_data=None, return_full=False):\n",
    "        '''\n",
    "        Evaluate a given recommender system. Evaluation data can be provided again to overwrite existing dataset.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        model: RecommenderSystem object (custom class)\n",
    "            Recommender system model to be evaluated. Assume model to have been fitted prior to evaluation.\n",
    "        eval_data: pandas.DataFrame, optional\n",
    "            Evaluation data to overwrite existing dataset. See update_data for details.\n",
    "        method: string, optional\n",
    "            Method with which to evaluate model performance. Will overwrite existing method.\n",
    "            Available options are 'precision@k' or 'map'\n",
    "        return_full: bool, optional (default: False)\n",
    "            Whether to include the full user-order scoring results versus just the aggreggated scores.\n",
    "        ----------\n",
    "        Returns: dict (return_full = False), or tuple(dict, pandas.DataFrame) (return_full = True)\n",
    "        '''\n",
    "        # Update data if provided\n",
    "        if eval_data is not None:\n",
    "            self.update_data(eval_data=eval_data)\n",
    "        # Update method if provided\n",
    "        if method is not None:\n",
    "            self.method = method\n",
    "        # Unset verbose in model\n",
    "        model.set_params(verbose=False)    \n",
    "        if self.method == 'precision@k':\n",
    "            eval_results = self.eval_pk(model)\n",
    "        elif self.method == 'map':\n",
    "            eval_results = self.eval_map(model)\n",
    "        else:\n",
    "            raise ValueError('method {} not recognized.'.format(self.method))\n",
    "        \n",
    "        if return_full:\n",
    "            return eval_results\n",
    "        else:\n",
    "            return eval_results[0]\n",
    "    \n",
    "    def eval_pk(self, model):\n",
    "        '''\n",
    "        Evaluate Precision@K for a given model\n",
    "        '''\n",
    "        dd_test = dd.from_pandas(self.eval_data, npartitions=self.N_CORES, sort=True)\n",
    "        \n",
    "        # Precompute user recommendations. Assumes n_range is within reasonable bounds.\n",
    "        user_recs = model.recommend(user_id=self.unique_users, n_rec=max(self.n_range))\n",
    "        \n",
    "        # Apply order_pk function to each order per user\n",
    "        dd_order_pk = dd_test.groupby(['user_id', 'order_id'])['product_id']\\\n",
    "                                     .apply(lambda x: order_pk(x, user_recs.loc[x.name[0]], k=self.n_range),\\\n",
    "                                            meta=('precison@k', float))\n",
    "        dd_order_pk = dd_order_pk.compute()\n",
    "        # Get results\n",
    "        order_pk_results = dd_order_pk.unstack()\n",
    "        order_pk_mean = order_pk_results.mean()\n",
    "        \n",
    "        # Convert to summary dict\n",
    "        global_metrics = {'model_name': model.MODEL_NAME, **order_pk_mean.to_dict()}\n",
    "        \n",
    "        return global_metrics, order_pk_results\n",
    "    \n",
    "    def eval_map(self, model):\n",
    "        '''\n",
    "        Evaluate MAP for a given model\n",
    "        '''\n",
    "        dd_test = dd.from_pandas(self.eval_data, npartitions=self.N_CORES, sort=True)\n",
    "        \n",
    "        # Precompute user recommendations. Assumes n_range is within reasonable bounds.\n",
    "        user_recs = model.recommend(user_id=self.unique_users, n_rec=max(self.n_range))\n",
    "        \n",
    "        # Apply order_pk function to each order per user\n",
    "        dd_order_map = dd_test.groupby(['user_id', 'order_id'])['product_id']\\\n",
    "                                     .apply(lambda x: order_map(x, user_recs.loc[x.name[0]], self.n_range),\\\n",
    "                                            meta=('precison@k', float))\n",
    "        dd_order_map = dd_order_map.compute()\n",
    "        # Get results\n",
    "        order_map_results = dd_order_map.unstack()\n",
    "        order_map_mean = order_map_results.mean()\n",
    "        \n",
    "        # Convert to summary dict\n",
    "        global_metrics = {'model_name': model.MODEL_NAME, **order_map_mean.to_dict()}\n",
    "        \n",
    "        return global_metrics, order_map_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mev = ModelEvaluator(eval_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_results = mev.evaluate_model(gpop_rec, method='precision@k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Global Popularity',\n",
       " 'p@05': 0.09323250000000875,\n",
       " 'p@10': 0.0866226984126957}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_results = mev.evaluate_model(gpop_rec, method='map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map@05': 0.057444861111113014,\n",
       " 'map@10': 0.04147721793902748,\n",
       " 'model_name': 'Global Popularity'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Popularity Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:64245\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:64246' target='_blank'>http://127.0.0.1:64246</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>34.31 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:64245' processes=8 cores=8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserPopularityRecommender(RecommenderSystem):\n",
    "    '''\n",
    "    Global Popularity Recommender system: produces recommendations based off most popular (i.e. frequently ordered)\n",
    "    items across all users.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_rec: int (default: 10)\n",
    "        Number of product recommendations to return. Setting to -1 will return all products ranked.\n",
    "    ----------\n",
    "    '''\n",
    "    MODEL_NAME = 'User Popularity'\n",
    "    \n",
    "    def fit(self, data):\n",
    "        '''\n",
    "        Fit recommender using prior order product data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pandas.DataFrame\n",
    "            Dataframe containing history of order products. Assumes format of one row per product ordered.\n",
    "            Must contain column of 'product_id' on which to sum frequencies.\n",
    "        ----------\n",
    "        '''\n",
    "        t_start = time.time()\n",
    "        if self.verbose: print('[{:.0f}s] Fit starting...'.format(time.time()-t_start))\n",
    "        # convert data to dask dataframe\n",
    "        dd_data = dd.from_pandas(data[['user_id', 'order_id', 'product_id']], npartitions=8)\n",
    "        # get global product counts\n",
    "        if self.verbose: print('[{:.0f}s] Getting global product counts'.format(time.time()-t_start))\n",
    "        self.glob_product_counts = dd_data['product_id'].value_counts().to_frame(name='glob_purchase_cnt').compute()\n",
    "        \n",
    "        # get user product counts\n",
    "        if self.verbose: print('[{:.0f}s] Getting user product counts'.format(time.time()-t_start))\n",
    "        self.user_product_counts = dd_data.groupby('user_id')['product_id'].apply(lambda x: x.value_counts(), meta=('user_purchase_cnt', int))\\\n",
    "                                                                            .to_frame()\\\n",
    "                                                                            .compute()\\\n",
    "                                                                            .reset_index(1).rename(columns={'level_1':'product_id'}) # extract product id from index\n",
    "        \n",
    "        if self.verbose: print('[{:.0f}s] Fit complete'.format(time.time()-t_start))\n",
    "        self.fitted = True\n",
    "    \n",
    "    def recommend(self, user_id, **kwargs):\n",
    "        '''\n",
    "        Recommend products for a given user. Note that given the nature of this global popularity recommender,\n",
    "        recommendations are the same for all users, but user_id can still be provided for consistency amongst\n",
    "        recommender system parameters.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        user_id: int or array-like, optional (default: 0)\n",
    "            User ID to produce recommendations for. Note that for this particular recommender system, recommendations\n",
    "            are the same for all users and this parameter is merely included for consistency amongst recommenders.\n",
    "        ----------\n",
    "        Returns: pandas.DataFrame, index = ['user_id', 'rank'], cols = ['product_id]\n",
    "        '''\n",
    "        # Check if fit was performed\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError('cannot recommend without fitting!')\n",
    "        # Overwrite params if provided\n",
    "        self.set_params(**kwargs)\n",
    "        \n",
    "        t_start = time.time()\n",
    "        if self.verbose: print('[{:.0f}s] Rec starting...'.format(time.time()-t_start))\n",
    "        \n",
    "        # Limit to top n_rec results per user\n",
    "        if self.verbose: print('[{:.0f}s] Getting top n user products'.format(time.time()-t_start))\n",
    "        user_data = self.user_product_counts.loc[user_id].reset_index()\n",
    "        top_user_product_counts =  dd.from_pandas(user_data, npartitions=8)\\\n",
    "                                     .groupby('user_id')[['product_id','user_purchase_cnt']]\\\n",
    "                                     .apply(lambda x: x.nlargest(self.n_rec, columns=['user_purchase_cnt']),\\\n",
    "                                            meta={'product_id': int, 'user_purchase_cnt': int})\\\n",
    "                                     .compute()\\\n",
    "                                     .reset_index(1, drop=True).reset_index() # clean up grouped indexing\n",
    "        \n",
    "        # create dataframe of user purchases with user & global purchase counts\n",
    "        if self.verbose: print('[{:.0f}s] Combining user and global purchase counts'.format(time.time()-t_start))\n",
    "        user_recs_df = top_user_product_counts.join(self.glob_product_counts, on='product_id')\n",
    "        # get additional recommendations for users with insufficient purchase histories\n",
    "        if self.verbose: print('[{:.0f}s] Getting additionl global recommendations per user'.format(time.time()-t_start))\n",
    "        def get_extra_glob_recs(user_recs, n_rec, global_product_counts):\n",
    "            '''\n",
    "            Helper function for getting additional recommendations to pad results up to n_rec\n",
    "            '''\n",
    "            n = user_recs.shape[0]\n",
    "            # Initialize dict of additional recs\n",
    "            new_data = {'product_id': [],\n",
    "                        'glob_purchase_cnt': [],\n",
    "                        'user_purchase_cnt': 0}\n",
    "            # If missing recs\n",
    "            if n < n_rec:\n",
    "                # n missing recs\n",
    "                n_delta = n_rec-n\n",
    "                # non-recommended products from global list\n",
    "                new_prods_mask = ~global_product_counts.index.isin(user_recs['product_id'].values)\n",
    "                # get top n recs to add\n",
    "                add_rec = global_product_counts[new_prods_mask][:n_delta]\n",
    "                # populate dict lists\n",
    "                new_data['product_id'] += add_rec.index.tolist()\n",
    "                new_data['glob_purchase_cnt'] += add_rec['glob_purchase_cnt'].values.tolist()\n",
    "            return pd.DataFrame(new_data)\n",
    "        \n",
    "        add_rec = dd.from_pandas(user_recs_df, npartitions=8)\n",
    "        add_rec = add_rec.groupby('user_id').apply(lambda x: get_extra_glob_recs(x, self.n_rec, self.glob_product_counts),\n",
    "                                                   meta={'product_id': int, 'glob_purchase_cnt': int, 'user_purchase_cnt': int})\\\n",
    "                                            .compute()\n",
    "        \n",
    "        # if any additional results\n",
    "        if add_rec.shape[0] > 0:\n",
    "            add_rec = add_rec.reset_index(1, drop=True).reset_index() # clean up grouped indexing\n",
    "            # combine user recs with additional recs\n",
    "            if self.verbose: print('[{:.0f}s] Combining original and additional recommendation results'.format(time.time()-t_start))\n",
    "            user_recs_df = pd.concat([user_recs_df, add_rec], ignore_index=True)\n",
    "        \n",
    "        # sort and index\n",
    "        self.user_recs_df = user_recs_df.sort_values(by=['user_id', 'user_purchase_cnt', 'glob_purchase_cnt'], ascending=[True, False, False]).set_index('user_id')\n",
    "        \n",
    "        self.fitted = True\n",
    "        if self.verbose: print('[{:.0f}s] Rec complete'.format(time.time()-t_start))\n",
    "\n",
    "        df_rec = self.user_recs_df.loc[user_id]['product_id']\n",
    "        \n",
    "        return super(UserPopularityRecommender, self).recommend(df_rec=df_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "upop_rec = UserPopularityRecommender(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0s] Fit starting...\n",
      "[0s] Getting global product counts\n",
      "[1s] Getting user product counts\n",
      "[5s] Fit complete\n"
     ]
    }
   ],
   "source": [
    "upop_rec.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0s] Rec starting...\n",
      "[0s] Getting top n user products\n",
      "[4s] Combining user and global purchase counts\n",
      "[4s] Getting additionl global recommendations per user\n",
      "[6s] Rec complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "7    40852\n",
       "7    17638\n",
       "7    37602\n",
       "7    21137\n",
       "7     4920\n",
       "7    31683\n",
       "7    13198\n",
       "7    42803\n",
       "7    30391\n",
       "7    43967\n",
       "Name: product_id, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upop_rec.recommend(user_id=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_results = mev.evaluate_model(upop_rec, method='precision@k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'User Popularity',\n",
       " 'p@05': 0.4033566666666485,\n",
       " 'p@10': 0.39397716269841737}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_results = mev.evaluate_model(upop_rec, method='map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map@05': 0.3180649583333421,\n",
       " 'map@10': 0.2706378651423558,\n",
       " 'model_name': 'User Popularity'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Popularity w/ Time Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserPopularityRecommender(RecommenderSystem):\n",
    "    '''\n",
    "    Global Popularity Recommender system: produces recommendations based off most popular (i.e. frequently ordered)\n",
    "    items across all users.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_rec: int (default: 10)\n",
    "        Number of product recommendations to return. Setting to -1 will return all products ranked.\n",
    "    decay: bool (default: True)\n",
    "        Whether to implement time decay to product recommendation ranking\n",
    "    decay_method: str (default: 'linear')\n",
    "        Method with which to decay product purchase values according to time of purchase.\n",
    "        Choice between 'linear' or 'exponential' decay methods.\n",
    "        Linear decay reduces products weight linearly toward 0 relative to the maximum order age present.\n",
    "        Exponential decay redced products weight according to calculated/provided half-life of the product.\n",
    "    decay_constant: float (default: None)\n",
    "        Decay parameter determining the strength of decay. Is automatically calculated if not provided\n",
    "        For linear decay, default value is 1. Values less than 1 will decrease decay rate, values above will increase decay rate.\n",
    "        For exponential decay, default value is median order age. Defining this parameter manually sets the half-life interval (scale dependent)\n",
    "        at which products weights decrease by half.\n",
    "        \n",
    "    ----------\n",
    "    '''\n",
    "    MODEL_NAME = 'User Popularity'\n",
    "    \n",
    "    def __init__(self, decay=True, decay_method='linear', decay_constant=None, **kwargs):\n",
    "        super(UserPopularityRecommender, self).__init__(**kwargs)\n",
    "        self.decay = decay\n",
    "        self.decay_method = decay_method\n",
    "        self.decay_constant = decay_constant\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.decay = kwargs.pop('decay', self.decay)\n",
    "        self.decay_method = kwargs.pop('decay_method', self.decay_method)\n",
    "        self.decay_constant = kwargs.pop('decay_constant', self.decay_constant)\n",
    "        super(UserPopularityRecommender, self).set_params(**kwargs)\n",
    "    \n",
    "    def get_params(self):\n",
    "        d = super(UserPopularityRecommender, self).get_params()\n",
    "        d['decay'] = self.decay\n",
    "        d['decay_method'] = self.decay_method\n",
    "        d['decay_constant'] = self.decay_constant\n",
    "        return d\n",
    "    \n",
    "    def fit(self, data):\n",
    "        '''\n",
    "        Fit recommender using prior order product data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pandas.DataFrame\n",
    "            Dataframe containing history of order products. Assumes format of one row per product ordered.\n",
    "            Must contain column of 'product_id' on which to sum frequencies.\n",
    "        ----------\n",
    "        '''\n",
    "        t_start = time.time()\n",
    "        if self.verbose: print('[{:.0f}s] Fit starting...'.format(time.time()-t_start))\n",
    "        data = data.copy()\n",
    "        \n",
    "        if self.decay:\n",
    "            if self.verbose:\n",
    "                print('[{:.0f}s] Adjusting purchase values for time decay'.format(time.time()-t_start))\n",
    "            # Fill NaN (i.e. the first orders) with 0\n",
    "            data['days_since_prior_order'].fillna(0, inplace=True)\n",
    "            \n",
    "            # Cumulative sum of days passed with progressing order numbers\n",
    "            order_times = data.groupby(['user_id', 'order_number'])[['days_since_prior_order']].mean().groupby(level=[0]).cumsum()\n",
    "            \n",
    "            # Rename columns\n",
    "            order_times.rename(columns={'days_since_prior_order': 'days_since_first_order'}, inplace=True)\n",
    "            \n",
    "            # Invert time scale (days since first order -> days since last order)\n",
    "            order_times['days_since_last_order'] = dd.from_pandas(order_times.reset_index(1), npartitions=8)\\\n",
    "                                                     .groupby('user_id')['days_since_first_order']\\\n",
    "                                                     .apply(lambda x: x.max()-x, meta=int)\n",
    "            self.order_times = order_times\n",
    "            # Merge new time values into original dataframe\n",
    "            data = data.merge(order_times, left_on = ['user_id', 'order_number'], right_index=True)\n",
    "            \n",
    "            if self.decay_method == 'linear':\n",
    "                if self.decay_constant is None:\n",
    "                    self.decay_constant = 1\n",
    "                t_max = data['days_since_last_order'].max()\n",
    "                t_min = 0\n",
    "                data['weighted_product_value'] = data['days_since_last_order'].apply(lambda x: max(0, 1 - self.decay_constant*(x/(t_max - t_min))))\n",
    "            \n",
    "            elif self.decay_method == 'exponential':\n",
    "                if self.decay_constant is None:\n",
    "                    # Default to half life being the median age of an order\n",
    "                    self.decay_constant = data['days_since_last_order'].median()*np.log(2)\n",
    "                data['weighted_product_value'] = np.exp(-1/self.decay_constant * data['days_since_last_order'])\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(\"decay method not recognized.\")\n",
    "                \n",
    "        else:\n",
    "            # All products get value of 1 without decay\n",
    "            data['weighted_product_value'] = 1\n",
    "            \n",
    "        # convert data to dask dataframe\n",
    "        dd_data = dd.from_pandas(data[['user_id', 'order_id', 'product_id', 'weighted_product_value']], npartitions=8)\n",
    "        # get global product counts\n",
    "        if self.verbose:\n",
    "            print('[{:.0f}s] Getting global product values'.format(time.time()-t_start))\n",
    "        self.glob_product_val = dd_data.groupby('product_id')['weighted_product_value'].sum()\\\n",
    "                                                                                       .to_frame(name='global_purchase_value')\\\n",
    "                                                                                       .compute()\\\n",
    "                                                                                       .sort_values(by='global_purchase_value')\n",
    "        \n",
    "        # get user product counts\n",
    "        if self.verbose:\n",
    "            print('[{:.0f}s] Getting user product values'.format(time.time()-t_start))\n",
    "        self.user_product_val = dd_data.groupby(['user_id','product_id'])['weighted_product_value'].sum()\\\n",
    "                                                                            .to_frame(name = 'user_purchase_value')\\\n",
    "                                                                            .compute()\\\n",
    "                                                                            .reset_index(1) # extract product id from index\n",
    "        \n",
    "        if self.verbose: print('[{:.0f}s] Fit complete'.format(time.time()-t_start))\n",
    "        self.fitted = True\n",
    "    \n",
    "    def recommend(self, user_id, **kwargs):\n",
    "        '''\n",
    "        Recommend products for a given user. Note that given the nature of this global popularity recommender,\n",
    "        recommendations are the same for all users, but user_id can still be provided for consistency amongst\n",
    "        recommender system parameters.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        user_id: int or array-like, optional (default: 0)\n",
    "            User ID to produce recommendations for. Note that for this particular recommender system, recommendations\n",
    "            are the same for all users and this parameter is merely included for consistency amongst recommenders.\n",
    "        ----------\n",
    "        Returns: pandas.DataFrame, index = ['user_id'], cols = ['product_id]\n",
    "        '''\n",
    "        # Check if fit was performed\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError('cannot recommend without fitting!')\n",
    "        # Overwrite params if provided\n",
    "        self.set_params(**kwargs)\n",
    "        \n",
    "        t_start = time.time()\n",
    "        if self.verbose: print('[{:.0f}s] Rec starting...'.format(time.time()-t_start))\n",
    "        \n",
    "        # Limit to top n_rec results per user\n",
    "        if self.verbose: print('[{:.0f}s] Getting top n user products'.format(time.time()-t_start))\n",
    "        user_data = self.user_product_val.loc[user_id].reset_index()\n",
    "        top_user_products =  dd.from_pandas(user_data, npartitions=8)\\\n",
    "                                     .groupby('user_id')[['product_id', 'user_purchase_value']]\\\n",
    "                                     .apply(lambda x: x.nlargest(self.n_rec, columns=['user_purchase_value']),\\\n",
    "                                            meta={'product_id': int, 'user_purchase_value': int})\\\n",
    "                                     .compute()\\\n",
    "                                     .reset_index(1, drop=True).reset_index() # clean up grouped indexing\n",
    "        \n",
    "        # create dataframe of user purchases with user & global purchase counts\n",
    "        if self.verbose: print('[{:.0f}s] Combining user and global purchase counts'.format(time.time()-t_start))\n",
    "        user_recs_df = top_user_products.join(self.glob_product_val, on='product_id')\n",
    "        # get additional recommendations for users with insufficient purchase histories\n",
    "        if self.verbose: print('[{:.0f}s] Getting additionl global recommendations per user'.format(time.time()-t_start))\n",
    "        def get_extra_glob_recs(user_recs, n_rec, global_product_counts):\n",
    "            '''\n",
    "            Helper function for getting additional recommendations to pad results up to n_rec\n",
    "            '''\n",
    "            n = user_recs.shape[0]\n",
    "            # Initialize dict of additional recs\n",
    "            new_data = {'product_id': [],\n",
    "                        'global_purchase_value': [],\n",
    "                        'user_purchase_value': 0}\n",
    "            # If missing recs\n",
    "            if n < n_rec:\n",
    "                # n missing recs\n",
    "                n_delta = n_rec-n\n",
    "                # non-recommended products from global list\n",
    "                new_prods_mask = ~global_product_counts.index.isin(user_recs['product_id'].values)\n",
    "                # get top n recs to add\n",
    "                add_rec = global_product_counts[new_prods_mask][:n_delta]\n",
    "                # populate dict lists\n",
    "                new_data['product_id'] += add_rec.index.tolist()\n",
    "                new_data['global_purchase_value'] += add_rec['global_purchase_value'].values.tolist()\n",
    "            return pd.DataFrame(new_data)\n",
    "        \n",
    "        add_rec = dd.from_pandas(user_recs_df, npartitions=8)\n",
    "        add_rec = add_rec.groupby('user_id').apply(lambda x: get_extra_glob_recs(x, self.n_rec, self.glob_product_val),\n",
    "                                                   meta={'product_id': int, 'global_purchase_value': int, 'user_purchase_value': int})\\\n",
    "                                            .compute()\n",
    "        \n",
    "        # if any additional results\n",
    "        if add_rec.shape[0] > 0:\n",
    "            add_rec = add_rec.reset_index(1, drop=True).reset_index() # clean up grouped indexing\n",
    "            add_rec = add_rec[['user_id', 'product_id', 'user_purchase_value', 'global_purchase_value']]\n",
    "            # combine user recs with additional recs\n",
    "            if self.verbose: print('[{:.0f}s] Combining original and additional recommendation results'.format(time.time()-t_start))\n",
    "            user_recs_df = pd.concat([user_recs_df, add_rec], ignore_index=True)\n",
    "        \n",
    "        # sort and index\n",
    "        self.user_recs_df = user_recs_df.sort_values(by=['user_id', 'user_purchase_value', 'global_purchase_value'], ascending=[True, False, False]).set_index('user_id')\n",
    "        \n",
    "        if self.verbose: print('[{:.0f}s] Rec complete'.format(time.time()-t_start))\n",
    "        df_rec = self.user_recs_df.loc[user_id]['product_id']\n",
    "        return super(UserPopularityRecommender, self).recommend(df_rec=df_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "upop_rec = UserPopularityRecommender(n_rec=10, decay=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0s] Fit starting...\n",
      "[0s] Adjusting purchase values for time decay\n",
      "[19s] Getting global product values\n",
      "[19s] Getting user product values\n",
      "[19s] Fit complete\n"
     ]
    }
   ],
   "source": [
    "upop_rec.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0s] Rec starting...\n",
      "[0s] Getting top n user products\n",
      "[1s] Combining user and global purchase counts\n",
      "[1s] Getting additionl global recommendations per user\n",
      "[1s] Combining original and additional recommendation results\n",
      "[1s] Rec complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "88    35384\n",
       "88    35921\n",
       "88     6104\n",
       "88    26856\n",
       "88    31513\n",
       "88    42150\n",
       "88    14245\n",
       "88    41275\n",
       "88    22138\n",
       "88    12327\n",
       "Name: product_id, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upop_rec.recommend(user_id = 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_results = mev.evaluate_model(upop_rec, method='precision@k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'User Popularity',\n",
       " 'p@05': 0.41637166666665215,\n",
       " 'p@10': 0.41233724206349714}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_results = mev.evaluate_model(upop_rec, method='map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'User Popularity',\n",
       " 'map@05': 0.3304408611111218,\n",
       " 'map@10': 0.2850165834356901}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimization via \"Grid Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_gs(recommender, train_data, test_data, param_dict, scoring = 'map', scoring_n_range = [5,10], verbose = False):\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    from sklearn.model_selection import ParameterGrid\n",
    "    param_grid = ParameterGrid(param_dict)\n",
    "    \n",
    "    if type(scoring) is not list:\n",
    "        scoring = [scoring]\n",
    "    \n",
    "    mev = ModelEvaluator(eval_data=test_data, n_range=scoring_n_range)\n",
    "    \n",
    "    gs_results = []\n",
    "    \n",
    "    for param_set in param_grid:\n",
    "        if verbose:\n",
    "            print('Performing evaluation for {}'.format(param_set))\n",
    "        \n",
    "        if verbose:\n",
    "            print('\\t{:30}'.format('Fitting...'), end='\\r')\n",
    "        rec = recommender\n",
    "        rec.set_params(**param_set, verbose=False)\n",
    "        rec.fit(train_data)\n",
    "        \n",
    "        scores = {}\n",
    "        for scoring_method in scoring:\n",
    "            if verbose:\n",
    "                print('\\t{:30}'.format(\"Evaluating '{}'...\".format(scoring_method)), end='\\r')\n",
    "            scores.update(mev.evaluate_model(rec, method = scoring_method))\n",
    "        \n",
    "        summary = {'params': param_set, **{**scores}}\n",
    "        try:\n",
    "            del summary['model_name']\n",
    "        except:\n",
    "            return summary\n",
    "        gs_results.append(summary)\n",
    "        \n",
    "        if verbose:\n",
    "            print('\\t{:30}'.format(\"Complete!\".format(scoring_method)))\n",
    "    \n",
    "    gs_results_df = pd.DataFrame(gs_results)\n",
    "    return gs_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sets = [{'decay': [False]},\n",
    "               {'decay': [True], 'decay_method': ['linear'], 'decay_constant': [0.5, 1, 1.5, 2.0]},\n",
    "               {'decay': [True], 'decay_method': ['exponential'], 'decay_constant': [None, 10, 20, 50, 100, 150, 200]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing evaluation for {'decay': False}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 0.5, 'decay_method': 'linear'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 1, 'decay_method': 'linear'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 1.5, 'decay_method': 'linear'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 2.0, 'decay_method': 'linear'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': None, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 10, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 20, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 50, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 100, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 150, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 200, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n"
     ]
    }
   ],
   "source": [
    "gs_results = recommender_gs(recommender = upop_rec,\n",
    "                            train_data = train, test_data = val,\n",
    "                            param_dict = param_sets,\n",
    "                            scoring = 'map',\n",
    "                            verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results.sort_values(by = \"map@10\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map@05</th>\n",
       "      <th>map@10</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.340463</td>\n",
       "      <td>0.293842</td>\n",
       "      <td>{'decay': True, 'decay_constant': 50, 'decay_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.339426</td>\n",
       "      <td>0.292888</td>\n",
       "      <td>{'decay': True, 'decay_constant': 100, 'decay_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.337759</td>\n",
       "      <td>0.291956</td>\n",
       "      <td>{'decay': True, 'decay_constant': None, 'decay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.337720</td>\n",
       "      <td>0.291143</td>\n",
       "      <td>{'decay': True, 'decay_constant': 2.0, 'decay_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.335601</td>\n",
       "      <td>0.289088</td>\n",
       "      <td>{'decay': True, 'decay_constant': 150, 'decay_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.334709</td>\n",
       "      <td>0.288556</td>\n",
       "      <td>{'decay': True, 'decay_constant': 1.5, 'decay_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.332193</td>\n",
       "      <td>0.286475</td>\n",
       "      <td>{'decay': True, 'decay_constant': 200, 'decay_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.330441</td>\n",
       "      <td>0.285017</td>\n",
       "      <td>{'decay': True, 'decay_constant': 1, 'decay_me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.327054</td>\n",
       "      <td>0.283086</td>\n",
       "      <td>{'decay': True, 'decay_constant': 20, 'decay_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.327086</td>\n",
       "      <td>0.281837</td>\n",
       "      <td>{'decay': True, 'decay_constant': 0.5, 'decay_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.319643</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>{'decay': True, 'decay_constant': 10, 'decay_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318643</td>\n",
       "      <td>0.272517</td>\n",
       "      <td>{'decay': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      map@05    map@10                                             params\n",
       "8   0.340463  0.293842  {'decay': True, 'decay_constant': 50, 'decay_m...\n",
       "9   0.339426  0.292888  {'decay': True, 'decay_constant': 100, 'decay_...\n",
       "5   0.337759  0.291956  {'decay': True, 'decay_constant': None, 'decay...\n",
       "4   0.337720  0.291143  {'decay': True, 'decay_constant': 2.0, 'decay_...\n",
       "10  0.335601  0.289088  {'decay': True, 'decay_constant': 150, 'decay_...\n",
       "3   0.334709  0.288556  {'decay': True, 'decay_constant': 1.5, 'decay_...\n",
       "11  0.332193  0.286475  {'decay': True, 'decay_constant': 200, 'decay_...\n",
       "2   0.330441  0.285017  {'decay': True, 'decay_constant': 1, 'decay_me...\n",
       "7   0.327054  0.283086  {'decay': True, 'decay_constant': 20, 'decay_m...\n",
       "1   0.327086  0.281837  {'decay': True, 'decay_constant': 0.5, 'decay_...\n",
       "6   0.319643  0.276316  {'decay': True, 'decay_constant': 10, 'decay_m...\n",
       "0   0.318643  0.272517                                   {'decay': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decay': True, 'decay_constant': 50, 'decay_method': 'exponential'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.loc[8]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sets = [{'decay': [True], 'decay_method': ['exponential'], 'decay_constant': np.arange(30,61,5)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing evaluation for {'decay': True, 'decay_constant': 30, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 35, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 40, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 45, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 50, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 55, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n",
      "Performing evaluation for {'decay': True, 'decay_constant': 60, 'decay_method': 'exponential'}\n",
      "\tComplete!                     \n"
     ]
    }
   ],
   "source": [
    "gs_results_2 = recommender_gs(recommender = upop_rec,\n",
    "                            train_data = train, test_data = val,\n",
    "                            param_dict = param_sets,\n",
    "                            scoring = 'map',\n",
    "                            verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results_2.sort_values(by = \"map@10\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map@05</th>\n",
       "      <th>map@10</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.341276</td>\n",
       "      <td>0.294563</td>\n",
       "      <td>{'decay': True, 'decay_constant': 60, 'decay_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.341145</td>\n",
       "      <td>0.294323</td>\n",
       "      <td>{'decay': True, 'decay_constant': 55, 'decay_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.340463</td>\n",
       "      <td>0.293842</td>\n",
       "      <td>{'decay': True, 'decay_constant': 50, 'decay_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.339234</td>\n",
       "      <td>0.292940</td>\n",
       "      <td>{'decay': True, 'decay_constant': 45, 'decay_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.337409</td>\n",
       "      <td>0.291745</td>\n",
       "      <td>{'decay': True, 'decay_constant': 40, 'decay_m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     map@05    map@10                                             params\n",
       "6  0.341276  0.294563  {'decay': True, 'decay_constant': 60, 'decay_m...\n",
       "5  0.341145  0.294323  {'decay': True, 'decay_constant': 55, 'decay_m...\n",
       "4  0.340463  0.293842  {'decay': True, 'decay_constant': 50, 'decay_m...\n",
       "3  0.339234  0.292940  {'decay': True, 'decay_constant': 45, 'decay_m...\n",
       "2  0.337409  0.291745  {'decay': True, 'decay_constant': 40, 'decay_m..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decay': True, 'decay_constant': 60, 'decay_method': 'exponential'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results_2.loc[6]['params']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
